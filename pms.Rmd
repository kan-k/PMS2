---
title: "Varscreen"
author: "Kan Keeratimahat"
date: "11/03/2024"
output: html_document
---

#11 Mar
Want to test a reconstruction of data for Lambda matrix, using Robust PCA.
I will test on a subset of data, so just for testing, I will use a centre mask that I created in `pms_extension_2.Rmd` in the folder PMS
which is done via
`submask[36:54,47:60,32:45] <- mask_subcor[36:54,47:60,32:45]`
table(submask[submask!=0]) #1613 voxels in total
saved as `'/well/nichols/users/qcv214/PMS/sub_centre_mask'`

I will also used a saved dataset from there with 4xxx subjects. Do not use this in the future
I will subset this to 100
```{r}
library(feather)
sub.dat <- read_feather('/well/nichols/users/qcv214/PMS/sub_dat.feather') #dim = 4263 124859
#Let's subset that to 100
sub.dat.test <- as.matrix(sub.dat[101:200,])
sub.dat <- as.matrix(sub.dat[1:100,])
```


##Get age response
```{r}
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
#These two are equal
part_use<-part_list[part_list$exist_vbm==1,] #4262 participants left
part_use<-part_use[1:200,] #only take 100

agetab<-read.table(file = '/well/nichols/projects/UKB/SMS/ukb_latest-Age.tsv', sep = '\t', header = TRUE)
age_tab<-as.data.frame(matrix(,nrow = length(part_use$V1),ncol = 2)) #id, age, number of masked voxels
colnames(age_tab)[1:2]<-c('id','age')
age_tab$id<-part_use$V1
for(i in 1:length(part_use$V1)){
  age_tab$age[i]<-agetab$X21003.2.0[agetab$eid_8107==sub(".", "",age_tab$id[i])]
}

age_tab.test <- age_tab[101:200,]
age_tab <- age_tab[1:100,]

```

###Fit with lasso
```{r}
library(glmnet)
set.seed(4)
fit <- cv.glmnet(sub.dat,age_tab$age, alpha=1)
coef.lasso <- coef(fit, s="lambda.min")
#Above is super sparse 
sum(coef.lasso!=0) #59 out of 1k... this is very sensitive to runs, some only have 16 selected
coef.selected <- rownames(coef.lasso)[which(coef.lasso!=0)]
```

####I will fit Ridge to obtain estimated beta
```{r}
set.seed(4)
fit.ridge <- cv.glmnet(sub.dat,age_tab$age, alpha=0)
beta <- coef(fit.ridge)
beta_no_int <- beta[-1,]
rank_beta.ridge <- beta_no_int[order(abs(beta_no_int), decreasing=TRUE)]
#y - xbeta
err <- as.numeric(age_tab$age - cbind(1,sub.dat)%*%beta)
```

### Robust PCA
####Robust PCA is calcualted based on `h` data points with smallest outlyingness measure used to compute cov matrix before pca

```{r}
library(rrcov) #Package for robust PCA
set.seed(4)
pca <- PcaHubert(sub.dat) #it only picks 10 PC ####Note that I need to change kmax to greater than 10
lambda <- pca$loadings[,10] %*% t(pca$loadings[,10]) 
Omeg <- solve(sub.dat%*%lambda%*%t(sub.dat) + (1e-5)*diag(nrow(sub.dat))) #4x4 
pre_beta_pms <- lambda%*%t(sub.dat)%*%Omeg #4 x 75

beta_pms <- beta[2:length(beta)] + pre_beta_pms%*%err
rownames(beta_pms) <- colnames(sub.dat)
#rank the absolute value of beta_pms with corresponding variable names
rank_beta_pms <- beta_pms[order(abs(beta_pms), decreasing=TRUE),]

nomean_beta_pms <- pre_beta_pms%*%err
rownames(nomean_beta_pms) <- colnames(sub.dat)
head(nomean_beta_pms[order(abs(nomean_beta_pms), decreasing=TRUE),],20)
```

###Vanilla PCA
```{r}
set.seed(4)
pca.normal <- prcomp(sub.dat)
#plot the variance explained
plot(pca.normal)
lambda.normal <- pca.normal$rotation[,10] %*% t(pca.normal$rotation[,10])
Omeg <- solve(sub.dat%*%lambda.normal%*%t(sub.dat) + (1e-5)*diag(nrow(sub.dat))) #4x4 
#Construct pre_beta_pms
pre_beta_pms.normal <- lambda.normal%*%t(sub.dat)%*%Omeg #4 x 75

beta_pms.normal <- beta[2:length(beta)] + pre_beta_pms.normal %*%err
rownames(beta_pms.normal) <- colnames(sub.dat)
#rank the absolute value of beta_pms with corresponding variable names
rank_beta_pms.normal <- beta_pms.normal[order(abs(beta_pms.normal), decreasing=TRUE),]

nomean_beta_pms.normal <- pre_beta_pms.normal%*%err
rownames(nomean_beta_pms.normal) <- colnames(sub.dat)
head(nomean_beta_pms.normal[order(abs(nomean_beta_pms.normal), decreasing=TRUE),],20)
```
#Let's look at overlap
```{r}
overlap <- function(rank_normal, rank_robust, k){
  top_k_normal <- names(rank_robust)[1:k]
  top_k <- names(rank_normal)[1:k]
  print(paste("Overlap of top", k, "variables:", length(intersect(top_k_normal, top_k)) ))
}

```
```{r}
for (i in c(10,54,100,200,500)){
  overlap(rank_beta_pms.normal,rank_beta_pms,i)
}
```

```{r}
ranked_nomean_beta_pms.normal <- nomean_beta_pms.normal[order(abs(nomean_beta_pms.normal), decreasing=TRUE),]
ranked_nomean_beta_pms <- nomean_beta_pms[order(abs(nomean_beta_pms), decreasing=TRUE),]
for (i in c(10,100,200)){
  overlap(ranked_nomean_beta_pms.normal,ranked_nomean_beta_pms,i)
}
```

```{r}
sum(coef.selected %in% names(ranked_nomean_beta_pms[1:500]))
```


### sd of data
```{r}
sd(age_tab$age)
```

###Let's do a prediction accuracy check with the same number of selected variables as LASSO by fitting ridge
```{r}
n.var <- length(coef.selected)-1 #minus intercept
yhat <- predict(fit, newx=sub.dat, s="lambda.min")
sqrt(mean((yhat - age_tab$age)^2)) #2.48
yhat.test <- predict(fit, newx=sub.dat.test, s="lambda.min")
sqrt(mean((yhat.test - age_tab.test$age)^2)) #2.48

```
How is lasso so low. ==> keep in mind this is training sample

###Ridge
```{r}
yhat <- predict(fit.ridge, newx=sub.dat, s="lambda.min")
sqrt(mean((yhat - age_tab$age)^2)) #2.48
yhat.test <- predict(fit.ridge, newx=sub.dat.test, s="lambda.min")
sqrt(mean((yhat.test - age_tab.test$age)^2)) #2.48
```
1.816

###Normal pca
```{r}
var.sel<- names(rank_beta_pms.normal[1:n.var])
fit.ridge.pca.normal <- cv.glmnet(sub.dat[,var.sel],age_tab$age, alpha=0)
beta <- coef(fit.ridge.pca.normal)
#y - xbeta
(rmse.normal <- sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat[,var.sel])%*%beta))^2)))
```

```{r}
var.sel<- names(rank_beta_pms.normal[1:500])
fit.ridge.pca.normal <- cv.glmnet(sub.dat[,var.sel],age_tab$age, alpha=0)
beta <- coef(fit.ridge.pca.normal)
#y - xbeta
(rmse.normal <- sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat[,var.sel])%*%beta))^2)))
(rmse.normal.test <- sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test[,var.sel])%*%beta))^2)))

```


###RobPCA
```{r}
var.sel<- names(rank_beta_pms[1:n.var])
fit.ridge.pca <- cv.glmnet(sub.dat[,var.sel],age_tab$age, alpha=0)
beta <- coef(fit.ridge.pca)
#y - xbeta
(rmse <- sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat[,var.sel])%*%beta))^2)))
```
```{r}
var.sel<- names(rank_beta_pms[1:500])
fit.ridge.pca <- cv.glmnet(sub.dat[,var.sel],age_tab$age, alpha=0)
beta <- coef(fit.ridge.pca)
#y - xbeta
(rmse <- sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat[,var.sel])%*%beta))^2)))
(rmse.test <- sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test[,var.sel])%*%beta))^2)))

```


#18 Mar

##To do
1. Change beta prior to 0 (or leave as ridge)
2. Compare this model against truncated ridge
3. Use Lambda to make prediction/fit model as well.
4. Visualise the power of selected pms stats 
5. Do held out performance /


##Assessing the improvement in voxels inclusion

```{r}
long.rmse <- function(ranked_coef, num.vox.vec){
  train <- vector(mode = 'numeric')
  test <- vector(mode = 'numeric')
  for(i in num.vox.vec){
    var.sel<- names(ranked_coef[1:i])
    fit.ridge.pca <- cv.glmnet(sub.dat[,var.sel],age_tab$age, alpha=0)
    beta <- coef(fit.ridge.pca)
    train <- c(train,sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat[,var.sel])%*%beta))^2)))
    test <- c(test,sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test[,var.sel])%*%beta))^2)))
  }
  out <- list()
  out$train <- train
  out$test <- test
  return(out)
}
```

```{r}
num.vox.vec <- (1:100)*10

res.ropca <- long.rmse(rank_beta_pms, num.vox.vec)
res.pca <- long.rmse(rank_beta_pms.normal, num.vox.vec)
res.ridge <- long.rmse(rank_beta.ridge, num.vox.vec)

```

##Plot bbs loss
```{r}
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.ropca$train,res.pca$train,res.ridge$train))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,5) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```

```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.ropca$test,res.pca$test,res.ridge$test))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(5.5,6.5) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

##Do selection with prior mu = 0
```{r}
#Robust PCA
set.seed(4)
pca <- PcaHubert(sub.dat) #it only picks 10 PC ####Note that I need to change kmax to greater than 10
lambda <- pca$loadings[,10] %*% t(pca$loadings[,10]) 
Omeg <- solve(sub.dat%*%lambda%*%t(sub.dat) + (1e-5)*diag(nrow(sub.dat))) #4x4 
pre_beta_pms <- lambda%*%t(sub.dat)%*%Omeg #4 x 75
beta_pms <- pre_beta_pms%*%age_tab$age
rownames(beta_pms) <- colnames(sub.dat)
rank_beta_pms <- beta_pms[order(abs(beta_pms), decreasing=TRUE),]


#PCA 
set.seed(4)
pca.normal <- prcomp(sub.dat)
lambda.normal <- pca.normal$rotation[,10] %*% t(pca.normal$rotation[,10])
Omeg <- solve(sub.dat%*%lambda.normal%*%t(sub.dat) + (1e-5)*diag(nrow(sub.dat))) #4x4 
pre_beta_pms.normal <- lambda.normal%*%t(sub.dat)%*%Omeg #4 x 75
beta_pms.normal <- pre_beta_pms.normal %*%age_tab$age
rownames(beta_pms.normal) <- colnames(sub.dat)
rank_beta_pms.normal <- beta_pms.normal[order(abs(beta_pms.normal), decreasing=TRUE),]
plot(cumsum(pca.normal$sdev^2)/sum(pca.normal$sdev^2), type = 'b')

```
This cumulative plot shows



```{r}
num.vox.vec <- (1:100)*10

res.ropca <- long.rmse(rank_beta_pms, num.vox.vec)
res.pca <- long.rmse(rank_beta_pms.normal, num.vox.vec)
res.ridge <- long.rmse(rank_beta.ridge, num.vox.vec)

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.ropca$train,res.pca$train,res.ridge$train))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,8) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```

```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.ropca$test,res.pca$test,res.ridge$test))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(5.5,8) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

The ridge result isn't adding up with the previous one. In the previous one, ridge had so much better training rmse than this. 

##Do predictions with Lambda incorporated
I believe this is just doing PMS with rows deleted. Actually lambda is p x p.
I think I will keep the same lambda structure but assign 0 to X instead.

##Create a function to calculate beta pms with zero-ed row of X
```{r}
long.rmse.with.lambda <- function(ranked_coef, num.vox.vec, lambda){
  train <- vector(mode = 'numeric')
  test <- vector(mode = 'numeric')
  for(i in num.vox.vec){
    var.sel<- names(ranked_coef[1:i])
    sub.dat.sub <- sub.dat
    sub.dat.test.sub <- sub.dat.test
    
    mask.out <- setdiff(colnames(sub.dat),var.sel)
    sub.dat.sub[,mask.out] <- 0
    sub.dat.test.sub[,mask.out] <- 0
    
    Omeg <- solve(sub.dat.sub%*%lambda%*%t(sub.dat.sub) + (1e-5)*diag(nrow(sub.dat.sub)))
    beta_pms <- lambda%*%t(sub.dat.sub)%*%Omeg%*%age_tab$age
    intercept <- mean(age_tab$age) - colMeans(sub.dat.sub)%*%beta_pms 
    
    beta <- c(intercept,beta_pms)
    train <- c(train,sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat.sub)%*%beta))^2)))
    test <- c(test,sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test.sub)%*%beta))^2)))
  }
  out <- list()
  out$train <- train
  out$test <- test
  return(out)
}
```

```{r}
num.vox.vec <- (1:100)*10

res.lambda.ropca <- long.rmse.with.lambda(rank_beta_pms, num.vox.vec,lambda)
res.lambda.pca <- long.rmse.with.lambda(rank_beta_pms.normal, num.vox.vec,lambda.normal)

```

```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$train,res.lambda.pca$train,res.ridge$train))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,30) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```

```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$test,res.lambda.pca$test,res.ridge$test))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(5.5,30) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

#21 March

Look at variance explained
##Do selection with prior mu = 0
```{r}
#Robust PCA
set.seed(4)
pca <- PcaHubert(sub.dat,kmax=100) #it only picks 10 PC ####Note that I need to change kmax to greater than 10
lambda <- pca$loadings[,36] %*% t(pca$loadings[,36]) 
Omeg <- solve(sub.dat%*%lambda%*%t(sub.dat) + (1e-5)*diag(nrow(sub.dat))) #4x4 
pre_beta_pms <- lambda%*%t(sub.dat)%*%Omeg #4 x 75
beta_pms <- pre_beta_pms%*%age_tab$age
rownames(beta_pms) <- colnames(sub.dat)
rank_beta_pms <- beta_pms[order(abs(beta_pms), decreasing=TRUE),]
pca.sum <- summary(pca)
```
Robust pca only allowed 53 PCs.... and variance explaied is 100%
Let's pick PCs such that it takes at least 90% of variance, which is 36 PCs


```{r}
#PCA 
set.seed(4)
pca.normal <- prcomp(sub.dat)
lambda.normal <- pca.normal$rotation[,72] %*% t(pca.normal$rotation[,72])
Omeg <- solve(sub.dat%*%lambda.normal%*%t(sub.dat) + (1e-5)*diag(nrow(sub.dat))) #4x4 
pre_beta_pms.normal <- lambda.normal%*%t(sub.dat)%*%Omeg #4 x 75
beta_pms.normal <- pre_beta_pms.normal %*%age_tab$age
rownames(beta_pms.normal) <- colnames(sub.dat)
rank_beta_pms.normal <- beta_pms.normal[order(abs(beta_pms.normal), decreasing=TRUE),]
plot(cumsum(pca.normal$sdev^2)/sum(pca.normal$sdev^2), type = 'b')
min(which(cumsum(pca.normal$sdev^2)/sum(pca.normal$sdev^2) > 0.9)) #72
```
This PCA cumulative plot shows that we need n = 99 or 100, or something way larger than 10.
Take 72 PCs then it explains 90% of variance explained

```{r}
num.vox.vec <- (1:100)*10

res.ropca <- long.rmse(rank_beta_pms, num.vox.vec)
res.pca <- long.rmse(rank_beta_pms.normal, num.vox.vec)
res.ridge <- long.rmse(rank_beta.ridge, num.vox.vec)

```
```{r}
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.ropca$train,res.pca$train,res.ridge$train))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,8) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```

```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.ropca$test,res.pca$test,res.ridge$test))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(5.5,8) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

##With lambda prediction
```{r}
num.vox.vec <- (1:100)*10

res.lambda.ropca <- long.rmse.with.lambda(rank_beta_pms, num.vox.vec,lambda)
res.lambda.pca <- long.rmse.with.lambda(rank_beta_pms.normal, num.vox.vec,lambda.normal)

```

```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$train,res.lambda.pca$train,res.ridge$train))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,30) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$test,res.lambda.pca$test,res.ridge$test))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(5.5,30) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```


#25 Mar

I need to perhaps scale this to larger images.

Before going into full images, lets scale it up 10 times?

##Get the sub Mask
```{r}
mask_subcor<-oro.nifti::readNIfTI('/well/nichols/users/qcv214/PMS/mask_without_WM_and_stem_thrsholded.nii.gz')

submask <-array(0,dim=dim(mask_subcor))
submask[26:64,37:70,22:55] <- mask_subcor[26:64,37:70,22:55] 
table(submask[submask!=0]) #1613 voxels in total
length(submask[submask!=0]) #15,847 voxels

writeNIfTI(submask,'/well/nichols/users/qcv214/pms2/sub150_centre_mask') #/well/nichols/users/qcv214/pms2

```

##Get age response
```{r}
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
#These two are equal
part_use<-part_list[part_list$exist_vbm==1,] #4262 participants left
part_use<-part_use[1:200,] #only take 100

agetab<-read.table(file = '/well/nichols/projects/UKB/SMS/ukb_latest-Age.tsv', sep = '\t', header = TRUE)
age_tab<-as.data.frame(matrix(,nrow = length(part_use$V1),ncol = 2)) #id, age, number of masked voxels
colnames(age_tab)[1:2]<-c('id','age')
age_tab$id<-part_use$V1
for(i in 1:length(part_use$V1)){
  age_tab$age[i]<-agetab$X21003.2.0[agetab$eid_8107==sub(".", "",age_tab$id[i])]
}
age_tab.test <- age_tab[101:200,]
age_tab <- age_tab[1:100,]
```

##Get data 
```{r}
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',age_tab$id,'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
sub.dat <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
colnames(sub.dat) <- as.character(1:ncol(sub.dat))
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',age_tab.test$id,'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
sub.dat.test <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
colnames(sub.dat.test) <- colnames(sub.dat)
```

## PMS
Look at variance explained
###Do selection with prior mu = 0
Ridge
```{r}
set.seed(4)
fit.ridge <- cv.glmnet(sub.dat,age_tab$age, alpha=0)
beta <- coef(fit.ridge)
beta_no_int <- beta[-1,]
rank_beta.ridge <- beta_no_int[order(abs(beta_no_int), decreasing=TRUE)]
```

```{r}
library(rrcov) #Package for robust PCA
#Robust PCA
set.seed(4)
pca <- PcaHubert(sub.dat,kmax=100) #it only picks 10 PC ####Note that I need to change kmax to greater than 10
#summary(pca) #look at the first PC that had cumulative variance of 90%
#lambda <- pca$loadings[,54] %*% t(pca$loadings[,54]) 
lambda <- pca$loadings %*% t(pca$loadings) 
Omeg <- solve(sub.dat%*%lambda%*%t(sub.dat) + (1e-5)*diag(nrow(sub.dat))) #4x4 
pre_beta_pms <- lambda%*%t(sub.dat)%*%Omeg #4 x 75
beta_pms <- pre_beta_pms%*%age_tab$age
rownames(beta_pms) <- colnames(sub.dat)
rank_beta_pms <- beta_pms[order(abs(beta_pms), decreasing=TRUE),]
pca.sum <- summary(pca)
```
Robust pca only allowed 53 PCs.... and variance explaied is 100%
Let's pick PCs such that it takes at least 90% of variance, which is 36 PCs


```{r}
#PCA 
set.seed(4)
pca.normal <- prcomp(sub.dat)
ind.touse <- min(which(cumsum(pca.normal$sdev^2)/sum(pca.normal$sdev^2) > 0.9)) #72
#lambda.normal <- pca.normal$rotation[,ind.touse] %*% t(pca.normal$rotation[,ind.touse])
lambda.normal <- pca.normal$rotation%*% t(pca.normal$rotation)
Omeg <- solve(sub.dat%*%lambda.normal%*%t(sub.dat) + (1e-5)*diag(nrow(sub.dat))) #4x4 
pre_beta_pms.normal <- lambda.normal%*%t(sub.dat)%*%Omeg #4 x 75
beta_pms.normal <- pre_beta_pms.normal %*%age_tab$age
rownames(beta_pms.normal) <- colnames(sub.dat)
rank_beta_pms.normal <- beta_pms.normal[order(abs(beta_pms.normal), decreasing=TRUE),]
plot(cumsum(pca.normal$sdev^2)/sum(pca.normal$sdev^2), type = 'b')
min(which(cumsum(pca.normal$sdev^2)/sum(pca.normal$sdev^2) > 0.9)) #81
```
This PCA cumulative plot shows that we need n = 99 or 100, or something way larger than 10.
Take 72 PCs then it explains 90% of variance explained

#calculate rmse without lambda
```{r}
long.rmse <- function(ranked_coef, num.vox.vec){
  train <- vector(mode = 'numeric')
  test <- vector(mode = 'numeric')
  for(i in num.vox.vec){
    var.sel<- names(ranked_coef[1:i])
    fit.ridge.pca <- cv.glmnet(sub.dat[,var.sel],age_tab$age, alpha=0)
    beta <- coef(fit.ridge.pca)
    train <- c(train,sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat[,var.sel])%*%beta))^2)))
    test <- c(test,sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test[,var.sel])%*%beta))^2)))
  }
  out <- list()
  out$train <- train
  out$test <- test
  return(out)
}
```

```{r}
num.vox.vec <- (1:100)*10

res.ropca <- long.rmse(rank_beta_pms, num.vox.vec)
res.pca <- long.rmse(rank_beta_pms.normal, num.vox.vec)
res.ridge <- long.rmse(rank_beta.ridge, num.vox.vec)

```
```{r}
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.ropca$train,res.pca$train,res.ridge$train))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(1,8) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```

```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.ropca$test,res.pca$test,res.ridge$test))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(5.5,8) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

Note that there is a HUGE difference between using Robust PCA with 90% variance and 100% variance, although the difference is (54 vs 66 PCs)


##With lambda prediction

```{r}
long.rmse.with.lambda <- function(ranked_coef, num.vox.vec, lambda){
  train <- vector(mode = 'numeric')
  test <- vector(mode = 'numeric')
  for(i in num.vox.vec){
    var.sel<- names(ranked_coef[1:i])
    sub.dat.sub <- sub.dat
    sub.dat.test.sub <- sub.dat.test
    
    mask.out <- setdiff(colnames(sub.dat),var.sel)
    sub.dat.sub[,mask.out] <- 0
    sub.dat.test.sub[,mask.out] <- 0
    
    Omeg <- solve(sub.dat.sub%*%lambda%*%t(sub.dat.sub) + (1e-5)*diag(nrow(sub.dat.sub)))
    beta_pms <- lambda%*%t(sub.dat.sub)%*%Omeg%*%age_tab$age
    intercept <- mean(age_tab$age) - colMeans(sub.dat.sub)%*%beta_pms 
    
    beta <- c(intercept,beta_pms)
    train <- c(train,sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat.sub)%*%beta))^2)))
    test <- c(test,sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test.sub)%*%beta))^2)))
  }
  out <- list()
  out$train <- train
  out$test <- test
  return(out)
}
```

```{r}
num.vox.vec <- (1:100)*10

res.lambda.ropca <- long.rmse.with.lambda(rank_beta_pms, num.vox.vec,lambda)
res.lambda.pca <- long.rmse.with.lambda(rank_beta_pms.normal, num.vox.vec,lambda.normal)

```

```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$train,res.lambda.pca$train,res.ridge$train))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(0,20) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$test,res.lambda.pca$test,res.ridge$test))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(5.5,15) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```




#26 Mar
Let's map back the brain images
```{r}
#ROBPCA
  #Full ROBPCA
  mask.temp <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz')
  mask.temp[mask.temp!=0] <- abs(c(beta_pms))
  mask.temp@datatype = 16
  mask.temp@bitpix = 32
  writeNIfTI(mask.temp,paste0('/well/nichols/users/qcv214/pms2/viz/sub150_robpca_pms'))

  #1k ROB PCA
  mask.temp <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz')
  thres.ind <- as.numeric(names(rank_beta_pms[1:1000]))
  beta_pms.temp <- abs(c(beta_pms))
  beta_pms.temp[-thres.ind] <- -1
  mask.temp[mask.temp!=0] <- beta_pms.temp
  mask.temp@datatype = 16
  mask.temp@bitpix = 32
  writeNIfTI(mask.temp,paste0('/well/nichols/users/qcv214/pms2/viz/sub150_robpca_pms_1000'))
  
#PCA
  #Full PCA
  mask.temp <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz')
  mask.temp[mask.temp!=0] <- abs(c(beta_pms.normal))
  mask.temp@datatype = 16
  mask.temp@bitpix = 32
  writeNIfTI(mask.temp,paste0('/well/nichols/users/qcv214/pms2/viz/sub150_pca_pms'))

  #1k PCA
  mask.temp <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz')
  thres.ind <- as.numeric(names(rank_beta_pms.normal[1:1000]))
  beta_pms.temp <- abs(c(beta_pms.normal))
  beta_pms.temp[-thres.ind] <- -1
  mask.temp[mask.temp!=0] <- beta_pms.temp
  mask.temp@datatype = 16
  mask.temp@bitpix = 32
  writeNIfTI(mask.temp,paste0('/well/nichols/users/qcv214/pms2/viz/sub150_pca_pms_1000'))

#Ridge
  #Full Ridge
  mask.temp <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz')
  mask.temp[mask.temp!=0] <- abs(c(beta_no_int))
  mask.temp@datatype = 16
  mask.temp@bitpix = 32
  writeNIfTI(mask.temp,paste0('/well/nichols/users/qcv214/pms2/viz/sub150_ridge'))

  #1k Ridge
  mask.temp <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz')
  thres.ind <- as.numeric(names(rank_beta.ridge[1:1000]))
  beta_pms.temp <- abs(c(beta_no_int))
  beta_pms.temp[-thres.ind] <- -1
  mask.temp[mask.temp!=0] <- beta_pms.temp
  mask.temp@datatype = 16
  mask.temp@bitpix = 32
  writeNIfTI(mask.temp,paste0('/well/nichols/users/qcv214/pms2/viz/sub150_ridge_1000'))


```

PCA only detect the very edge of the image somehow. Look at 45,56,21
Ridge is somewhat smooth, centred around the thalamas as usual
ROBPCA is alright, less smooth than ridge somehow.

Let's see if PCA is picking up noises from the edges. by looking at s.d. 
sapply(df, sd)

```{r}
##Standard deviation
#Load data, see `list_of_all_images` the chunk before this.
sub.dat <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
colnames(sub.dat) <- as.character(1:ncol(sub.dat))
mask.temp <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz')
  mask.temp[mask.temp!=0] <- apply(sub.dat, 2, sd)
  mask.temp@datatype = 16
  mask.temp@bitpix = 32
  writeNIfTI(mask.temp,paste0('/well/nichols/users/qcv214/pms2/viz/sub150_sd'))
```

s.d. does not reveal anything funny that would go with the PCA odd behaviour

Assessing the odd behaviour
```{r}
plot(y=abs(c(beta_pms.normal)),x=1:15847, ylab ="Magnitude of PMS statistics",xlab = "Voxel number",main = "PMS: PCA")
plot(y=abs(c(beta_pms)),x=1:15847, ylab ="Magnitude of PMS statistics",xlab = "Voxel number",main = "PMS: Robust PCA")
plot(y=abs(c(beta_no_int)),x=1:15847, ylab ="Magnitude of Ridge",xlab = "Voxel number",main = "Ridge")

```

I will address the index of each voxel and match it with PCA
```{r}
mask.temp <-oro.nifti::readNIfTI('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz')
mask.temp[mask.temp!=0] <- 1:sum(c(mask.temp!=0))
mask.temp@datatype = 16
mask.temp@bitpix = 32
writeNIfTI(mask.temp,paste0('/well/nichols/users/qcv214/pms2/viz/sub150_centre_mask_index'))
```



#3 apr
##To do 
1. Fix lambda, do subsetting instead of masking out
2. Do cross validation on theta


##Subsetting lambda
```{r}
long.rmse.with.lambda <- function(ranked_coef, num.vox.vec, lambda){
  train <- vector(mode = 'numeric')
  test <- vector(mode = 'numeric')
  for(i in num.vox.vec){
    var.sel<- names(ranked_coef[1:i])
    sub.dat.sub <- sub.dat
    sub.dat.test.sub <- sub.dat.test
    
    mask.out <- as.numeric(setdiff(colnames(sub.dat),var.sel))
    #print(head(mask.out))
    
    sub.dat.sub <- sub.dat.sub[,-c(mask.out)] 
    sub.dat.test.sub<- sub.dat.test.sub[,-c(mask.out)] 
    
    lambda.sub <- lambda[-c(mask.out),-c(mask.out)]
    
    Omeg <- solve(sub.dat.sub%*%lambda.sub%*%t(sub.dat.sub) + (1e-5)*diag(nrow(sub.dat.sub)))
    beta_pms <- lambda.sub%*%t(sub.dat.sub)%*%Omeg%*%age_tab$age
    intercept <- mean(age_tab$age) - colMeans(sub.dat.sub)%*%beta_pms 
    
    beta <- c(intercept,beta_pms)
    train <- c(train,sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat.sub)%*%beta))^2)))
    test <- c(test,sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test.sub)%*%beta))^2)))
  }
  out <- list()
  out$train <- train
  out$test <- test
  return(out)
}
```

```{r}
num.vox.vec <- (1:100)*10

res.lambda.ropca <- long.rmse.with.lambda(rank_beta_pms, num.vox.vec,lambda)
res.lambda.pca <- long.rmse.with.lambda(rank_beta_pms.normal, num.vox.vec,lambda.normal)

```

```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$train,res.lambda.pca$train,res.ridge$train))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(0,20) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$test,res.lambda.pca$test,res.ridge$test))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(5.5,15) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
PCA gets even worse
How is it that for robust pca, training rmse keeps increasing but test rmse keep decreasing

##Cross validation

Let's start with the simplest version:
 - Keep train, test the same (ie 50-50)
 - Only look at performance at 1000 selected variables
 
###simplest version
```{r}
library(rrcov)
simple.cv.robpca <- function(no.variable = 1000,theta.range = 10^seq(-9,1,1)){ #-9
  train <- vector(mode = 'numeric')
  test <- vector(mode = 'numeric')
  pca <- PcaHubert(sub.dat,kmax=100) 
  lambda <- pca$loadings %*% t(pca$loadings) 
  for(theta in theta.range){
    #doing PCA
    Omeg <- solve(sub.dat%*%lambda%*%t(sub.dat) + (theta)*diag(nrow(sub.dat))) #4x4 
    pre_beta_pms <- lambda%*%t(sub.dat)%*%Omeg #4 x 75
    beta_pms <- pre_beta_pms%*%age_tab$age
    rownames(beta_pms) <- colnames(sub.dat)
    rank_beta_pms <- beta_pms[order(abs(beta_pms), decreasing=TRUE),]
    
    #Doing prediction
    var.sel<- names(rank_beta_pms[1:no.variable])
    sub.dat.sub <- sub.dat
    sub.dat.test.sub <- sub.dat.test
    
    mask.out <- as.numeric(setdiff(colnames(sub.dat),var.sel))
    #print(head(mask.out))
    
    sub.dat.sub <- sub.dat.sub[,-c(mask.out)] 
    sub.dat.test.sub<- sub.dat.test.sub[,-c(mask.out)] 
    
    lambda.sub <- lambda[-c(mask.out),-c(mask.out)]
    
    Omeg <- solve(sub.dat.sub%*%lambda.sub%*%t(sub.dat.sub) + (theta)*diag(nrow(sub.dat.sub)))
    beta_pms <- lambda.sub%*%t(sub.dat.sub)%*%Omeg%*%age_tab$age
    intercept <- mean(age_tab$age) - colMeans(sub.dat.sub)%*%beta_pms 
    
    beta <- c(intercept,beta_pms)
    train <- c(train,sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat.sub)%*%beta))^2)))
    test <- c(test,sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test.sub)%*%beta))^2)))
  }
  out <- rbind(theta.range,train,test)
  return(out)
}
```

```{r}
robpca.cv <- simple.cv.robpca()
```
Lowest theta is better, lowesr than this will lead to singularity

```{r}
simple.cv.pca <- function(no.variable = 1000,theta.range = 10^seq(-9,3,1)){
  train <- vector(mode = 'numeric')
  test <- vector(mode = 'numeric')
  pca <-  prcomp(sub.dat)
  lambda <- pca$rotation%*% t(pca$rotation)
  for(theta in theta.range){
    #doing PCA
    Omeg <- solve(sub.dat%*%lambda%*%t(sub.dat) + (theta)*diag(nrow(sub.dat))) #4x4 
    pre_beta_pms <- lambda%*%t(sub.dat)%*%Omeg #4 x 75
    beta_pms <- pre_beta_pms%*%age_tab$age
    rownames(beta_pms) <- colnames(sub.dat)
    rank_beta_pms <- beta_pms[order(abs(beta_pms), decreasing=TRUE),]
    
    #Doing prediction
    var.sel<- names(rank_beta_pms[1:no.variable])
    sub.dat.sub <- sub.dat
    sub.dat.test.sub <- sub.dat.test
    
    mask.out <- as.numeric(setdiff(colnames(sub.dat),var.sel))
    #print(head(mask.out))
    
    sub.dat.sub <- sub.dat.sub[,-c(mask.out)] 
    sub.dat.test.sub<- sub.dat.test.sub[,-c(mask.out)] 
    
    lambda.sub <- lambda[-c(mask.out),-c(mask.out)]
    
    Omeg <- solve(sub.dat.sub%*%lambda.sub%*%t(sub.dat.sub) + (theta)*diag(nrow(sub.dat.sub)))
    beta_pms <- lambda.sub%*%t(sub.dat.sub)%*%Omeg%*%age_tab$age
    intercept <- mean(age_tab$age) - colMeans(sub.dat.sub)%*%beta_pms 
    
    beta <- c(intercept,beta_pms)
    train <- c(train,sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat.sub)%*%beta))^2)))
    test <- c(test,sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test.sub)%*%beta))^2)))
  }
  out <- rbind(theta.range,train,test)
  return(out)
}
```
```{r}
pca.cv <- simple.cv.pca() #theta = 10 is optimal
```

Now let's assess the outcome:
```{r}
long.rmse.with.lambda.theta <- function(lambda,theta,num.vox.vec){
  Omeg <- solve(sub.dat%*%lambda%*%t(sub.dat) + (theta)*diag(nrow(sub.dat))) #4x4 
  pre_beta_pms <- lambda%*%t(sub.dat)%*%Omeg #4 x 75
  beta_pms <- pre_beta_pms%*%age_tab$age
  rownames(beta_pms) <- colnames(sub.dat)
  rank_beta_pms <- beta_pms[order(abs(beta_pms), decreasing=TRUE),]
  train <- vector(mode = 'numeric')
  test <- vector(mode = 'numeric')
  for(i in num.vox.vec){
    var.sel<- names(rank_beta_pms[1:i])
    sub.dat.sub <- sub.dat
    sub.dat.test.sub <- sub.dat.test
    
    mask.out <- as.numeric(setdiff(colnames(sub.dat),var.sel))
    
    sub.dat.sub <- sub.dat.sub[,-c(mask.out)] 
    sub.dat.test.sub<- sub.dat.test.sub[,-c(mask.out)] 
    
    lambda.sub <- lambda[-c(mask.out),-c(mask.out)]
    
    Omeg <- solve(sub.dat.sub%*%lambda.sub%*%t(sub.dat.sub) + (theta)*diag(nrow(sub.dat.sub)))
    beta_pms <- lambda.sub%*%t(sub.dat.sub)%*%Omeg%*%age_tab$age
    intercept <- mean(age_tab$age) - colMeans(sub.dat.sub)%*%beta_pms 
    
    beta <- c(intercept,beta_pms)
    train <- c(train,sqrt(mean((as.numeric(age_tab$age - cbind(1,sub.dat.sub)%*%beta))^2)))
    test <- c(test,sqrt(mean((as.numeric(age_tab.test$age - cbind(1,sub.dat.test.sub)%*%beta))^2)))
  }
  out <- list()
  out$train <- train
  out$test <- test
  return(out)
}
```

```{r}
#Get lambda and lambda.normal
pca <- PcaHubert(sub.dat,kmax=100) 
lambda <- pca$loadings %*% t(pca$loadings) 

pca <-  prcomp(sub.dat)
lambda.normal <- pca$rotation%*% t(pca$rotation)
```


```{r}
num.vox.vec <- (1:100)*10

res.lambda.ropca <- long.rmse.with.lambda.theta(lambda, robpca.cv[1,which.min(robpca.cv[3,])], num.vox.vec)
res.lambda.pca <- long.rmse.with.lambda.theta(lambda.normal, pca.cv[1,which.min(pca.cv[3,])], num.vox.vec)

```

```{r}
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$train,res.lambda.pca$train,res.ridge$train))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(0,10) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res.lambda.ropca$test,res.lambda.pca$test,res.ridge$test))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(5.5,10) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

#14 Apr
Running 
//apr14_cv_pms 53813310 ===> with res3 mask and saliency [failed to create viz due to out of memory but not sure where]

```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/apr14_cv_pms.csv")
```

```{r}
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:3,])
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(0,15) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[4:6,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(4.5,15) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```



#19 Apr
//apr19_cv_pms 54561372 ===> centre mask, with 2k train/test
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/apr19_cv_pms.csv")
```
```{r}
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:3,])
num.vox.vec <- (1:100)*10
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,13) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[4:6,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(4,12.5) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
looks alright

I need to incorporate double tuning for screening and predictions
//apr21_dcv_pms 54576737 ===> double cv
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/apr21_dcv_pms.csv")
```
```{r}
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:3,])
num.vox.vec <- (1:100)*10
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,13) +
  theme_minimal() +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[4:6,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(4,12.5) +
  theme_minimal() +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```


//apr21_dcv_pms  54587542 ==> added viz, let's see.

#22 Apr
Perhaps extend this further, let's say 4k subjects.

see
```{r}
num.add <- 4000
part_use<- (read.csv('/well/nichols/users/qcv214/bnn2/add_1_part_id_use_final.txt')$V1)[1:num.add] #This file has 4258 additional subjects
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_use,'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
res3.dat <- rbind(res3.dat,as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz')))
age_tab<- rbind(age_tab,(read_feather('/well/nichols/users/qcv214/bnn2/res3/age_add1.feather'))[1:num.add,]) #Need to fix this
```

##Testing more data
###What is originally here, with loading current data
```{r}
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
#These two are equal
part_use<-part_list[part_list$exist_vbm==1,] #4262 participants left
#part_use<-part_use[1:200,] #only take 200
part_use<-part_use[1:4000,] #only take 4k

agetab<-read.table(file = '/well/nichols/projects/UKB/SMS/ukb_latest-Age.tsv', sep = '\t', header = TRUE)
age_tab<-as.data.frame(matrix(,nrow = length(part_use$V1),ncol = 2)) #id, age, number of masked voxels
colnames(age_tab)[1:2]<-c('id','age')
age_tab$id<-part_use$V1
for(i in 1:length(part_use$V1)){
  age_tab$age[i]<-agetab$X21003.2.0[agetab$eid_8107==sub(".", "",age_tab$id[i])]
}
#age_tab.test <- age_tab[101:200,]
#age_tab <- age_tab[1:100,]
age_tab.test <- age_tab[2001:4000,]
age_tab <- age_tab[1:2000,]
```
### More data
First needa check if their id overlap (don't want) //
```{r} 
age_tab2<-read_feather('/well/nichols/users/qcv214/bnn2/res3/age_add1.feather')
#sum(age_tab$id %in% age_tab2$id) =0 ==> no overlap
```

Found that some of the data on age_add1 is no longer there, let's create a new one.
```{r}
part_list2 <- read.csv('/well/nichols/users/qcv214/bnn2/add_1_part_id_use_final.txt')$V1 #4258
part_list2.exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list2,'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')) #4257, only one person is missing
part_use2 <-part_list2[part_list2.exist_vbm]
part_use2 <- part_use2[1:4000]
###
age_tab2<-as.data.frame(matrix(,nrow = length(part_use2),ncol = 2)) #id, age, number of masked voxels
colnames(age_tab2)[1:2]<-c('id','age')
age_tab2$id<-part_use2
for(i in 1:length(part_use2)){
  age_tab2$age[i]<-agetab$X21003.2.0[agetab$eid_8107==sub(".", "",age_tab2$id[i])]
}
```
Sanity check for completness of extraction
`sum(c(is.na(age_tab2)))` = 0


//apr22_dcv_pms  54664383 ==> added 4k more training, so 6k in total, note that num.vox.vec is changed to `(1:100)*100`

#apr 23
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/apr23_dcv_pms.csv")
```
```{r}
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:3,])
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[4:6,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(4,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

#9 May

We want to try incorportaing response into the projection matrix. There are options:
1. Partial Least Squares
2. Canonical Correlation Analysis (CCA)
3. Supervised PCA 


##Prepping data
###Get the sub Mask
```{r}
mask_subcor<-oro.nifti::readNIfTI('/well/nichols/users/qcv214/PMS/mask_without_WM_and_stem_thrsholded.nii.gz')

submask <-array(0,dim=dim(mask_subcor))
submask[26:64,37:70,22:55] <- mask_subcor[26:64,37:70,22:55] 
table(submask[submask!=0]) #1613 voxels in total
length(submask[submask!=0]) #15,847 voxels

# writeNIfTI(submask,'/well/nichols/users/qcv214/pms2/sub150_centre_mask') #/well/nichols/users/qcv214/pms2

```

###Get age response
```{r}
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
#These two are equal
part_use<-part_list[part_list$exist_vbm==1,] #4262 participants left
part_use<-part_use[1:200,] #only take 100

agetab<-read.table(file = '/well/nichols/projects/UKB/SMS/ukb_latest-Age.tsv', sep = '\t', header = TRUE)
age_tab<-as.data.frame(matrix(,nrow = length(part_use$V1),ncol = 2)) #id, age, number of masked voxels
colnames(age_tab)[1:2]<-c('id','age')
age_tab$id<-part_use$V1
for(i in 1:length(part_use$V1)){
  age_tab$age[i]<-agetab$X21003.2.0[agetab$eid_8107==sub(".", "",age_tab$id[i])]
}
age_tab.test <- age_tab[101:200,]
age_tab <- age_tab[1:100,]
```

###Get data 
```{r}
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',age_tab$id,'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
sub.dat <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
colnames(sub.dat) <- as.character(1:ncol(sub.dat))
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',age_tab.test$id,'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
sub.dat.test <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
colnames(sub.dat.test) <- colnames(sub.dat)
```


##Let's try PLS


```{r}
library(pls)

# Assuming 'X' is your predictor matrix and 'Y' is your response variable

# Perform PLS
pls_model <- plsr(age_tab$age ~ sub.dat)

# Projection of X onto the first few PLS components
scores <- scores(pls_model)

# Projection matrix
projection_matrix_pls <- loadings(pls_model) %*% t(loadings(pls_model)) #15847 x 15847

#print(projection_matrix_pls)

```


Running
//may9_dcv_pls_200 58015346 ==> 100 train subjects [super fast]
may9_dcv_pls 58020343 ==>6k subjects


##Result pls 200
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/may9_dcv_pls_200.csv")

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1,])
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("PLS")
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

##########################################.      Test
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[2,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("PLS")
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(4,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

##Result pls 6k
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/may9_dcv_pls.csv")

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1,])
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("PLS")
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

##########################################.      Test
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[2,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("PLS")
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(4,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```



###Old results (6k test subjects)
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/apr23_dcv_pms.csv")
```
```{r}
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:3,])
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

```
```{r}
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[4:6,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(4,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

Running
//may9_dcv_spca 58149945

##Result spca 6k
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/may9_dcv_spca.csv")

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1,])
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("SPCA")
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

##########################################.      Test
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[2,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("SPCA")
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(4,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

#14 May

Aggregate the result
```{r}
library(ggplot2)
library(tidyr)
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/apr23_dcv_pms.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/may9_dcv_pls.csv")
res3 <- read.csv("/well/nichols/users/qcv214/pms2/pile/may9_dcv_spca.csv")


# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[1:3,],res2[1,],res3[1,]))
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge','PLS','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")


# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[4:6,],res2[2,],res3[2,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge','PLS','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  ylim(4,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

Use ridge to make predictions to make all methods comparaable, this is a variable screening exercise, not prediction

Running cv_pms2.R to obtain  ===> robca, pca, pls, spca for variable screening, then Ridge for prediction
`may27_cv_pms`



I keep running into problem. Here is a smaller version (500 train, 100 test) `cv_pms_600`
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/may27_cv_pms_600.csv")

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:5,])
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge','PLS','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[6:10,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge','PLS','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```






may27_cv_pms 61402365 ==> 6k data 

#2 June

2 methods (SPCA) methods since last meeting
- Fit Ridge on X,Y => Re-weight X => Screen out new X based on magnitude => Fit Robust PCA
- Fit ridge to screen out => apply SPCA

Let's try the first way on 4 test, 2 train?
```{r}
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
#These two are equal
part_use<-part_list[part_list$exist_vbm==1,] #4262 participants left
part_use<-part_use[1:6,] #only take 200
# part_use<-part_use[1:4000,] #only take 4k

agetab<-read.table(file = '/well/nichols/projects/UKB/SMS/ukb_latest-Age.tsv', sep = '\t', header = TRUE)
age_tab<-as.data.frame(matrix(,nrow = length(part_use$V1),ncol = 2)) #id, age, number of masked voxels
colnames(age_tab)[1:2]<-c('id','age')
age_tab$id<-part_use$V1
for(i in 1:length(part_use$V1)){
  age_tab$age[i]<-agetab$X21003.2.0[agetab$eid_8107==sub(".", "",age_tab$id[i])]
}
age_tab.test <- age_tab[5:6,]
age_tab <- age_tab[1:4,]
n.train <- nrow(age_tab)

list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',age_tab$id,'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
sub.dat <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
# sub.dat <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz'))

colnames(sub.dat) <- as.character(1:ncol(sub.dat))
list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',age_tab.test$id,'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
sub.dat.test <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
# sub.dat.test <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz'))

colnames(sub.dat.test) <- colnames(sub.dat)

cv_model <- cv.glmnet(sub.dat, age_tab$age, alpha = 0, nfolds = 10)
# Best lambda from cross-validation
coefficients <- coef(cv_model, s = "lambda.min")  # Extract coefficients at best lambda
weights <- abs(coefficients[-1,])  # Exclude intercept from weights (first row of coefficients)
X_weighted <- scale(sub.dat) * sqrt(weights) #there are 192 NAs in scale(sub.dat) but i dont know where *I believe it's to do with the column being a constant

#Question is do I rank the voxels by col mean or col var. I am guessing it's col var
colvar <- apply(X_weighted,MARGIN = 2, var)

rank_var.ridge <- colvar[order(colvar, decreasing=TRUE)]
var.sel<- names(rank_var.ridge[1:round(length(colvar)*0.3)]) #take only 30% of voxel

X_weighted_sel <- X_weighted[,var.sel]

pca <- PcaHubert(X_weighted_sel,kmax=min(n.train, length(var.sel))) 
lambda. <- pca$loadings %*% t(pca$loadings) 
```

Running
`june2_cv_pms_ridgeSRPCA` from `cv_pms2_rsrpca` 61555120 ==> exceeded time limit??


#5 june
may27_cv_pms takes like 15-17 hours
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/may27_cv_pms.csv")

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:5,])
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge','PLS','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[6:10,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge','PLS','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```


#9 June
Let's try fast MCD method to derive a robust covariance matrix then construct PCA
```{r}
# Load the necessary libraries
library(robustbase)
library(stats)

# Load and prepare your data
data <- mtcars

# Compute the MCD covariance matrix
mcd_result <- covMcd(data)
mcd_cov <- mcd_result$cov

# Perform eigen decomposition on the covariance matrix
eig_decomp <- eigen(mcd_cov)

# Extract the eigenvectors
eigenvectors <- eig_decomp$vectors

# The eigenvectors form the projection matrix
projection_matrix <- eigenvectors

# Print the projection matrix
print("Projection Matrix (Eigenvectors):")
print(projection_matrix)

# Center the data using the robust center
data_centered <- scale(data, center = mcd_result$center, scale = FALSE)

# Project the centered data onto the principal components
pca_scores <- data_centered %*% projection_matrix

# Print the first few principal component scores
print("Principal Component Scores:")
print(head(pca_scores))
```

Running 
june9_cv_pms_ridgeSMCDPCA 62725139

When I tried to run `june9_cv_pms_ridgeSMCDPCA_600`, I got this error from `covMcd(X_weighted_sel)` saying `Error in covMcd(X_weighted_sel) : n <= p -- you can't be serious!`.


10/6/2024
Tom's suggestion: use rank transofrmation (see Teams)
So across subjects, for each voxel, apply this transformation to transform the data (to get rid of outliers), then apply PCA.




#11 June
trying ridge +SPCA or ridge + SRPCA
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/may27_cv_pms_600.csv")
res2<- read.csv("/well/nichols/users/qcv214/pms2/pile/june11_cv_pms_ridgeSPCA_600.csv") #max 4700 variables
res2<-  cbind(res2,matrix(data=NA,nrow=nrow(res2), ncol = (length(res)-length(res2))))
colnames(res2) <- colnames(res)
res3 <- read.csv("/well/nichols/users/qcv214/pms2/pile/june11_cv_pms_ridgeSRPCA_600.csv")
res3<-  cbind(res3,matrix(data=NA,nrow=nrow(res3), ncol = (length(res)-length(res3))))
colnames(res3) <- colnames(res)

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[1:5,],res2[1,],res3[1,]))
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge','PLS','SPCA',"Ridge+SPCA","Ridge+SRPCA")
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[6:10,],res2[2,],res3[2,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c("RoPCA",'PCA','Ridge','PLS','SPCA',"Ridge+SPCA","Ridge+SRPCA")
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```


##Quantile normalisation
Correcting outlier in data across subjects for each voxels

`bestNormalize` not available
```{r}
if (!require("pacman")) {install.packages("pacman");library(pacman)}
p_load(bestNormalize)
inorm <- function(x) {
  orderNorm(x,warn=FALSE)$x.t * sd(x,na.rm=TRUE) + mean(x,na.rm=TRUE)
}
```


```{r}
# Quantile normalization function for a vector using inverse CDF of standard Gaussian
quantile_normalize_vector <- function(x) {
  # Remove NA values and get their ranks
  na_idx <- is.na(x)
  x_no_na <- x[!na_idx]
  
  # Compute the ranks
  ranks <- rank(x_no_na, ties.method = "average")
  
  # Map ranks to uniform [0, 1] probabilities
  n <- length(x_no_na)
  uniform_probs <- (ranks - 0.5) / n
  
  # Apply the inverse CDF of the standard Gaussian distribution
  normal_scores <- qnorm(uniform_probs)
  
  # Normalize to the original scale
  x_normalized <- normal_scores * sd(x_no_na, na.rm = TRUE) + mean(x_no_na, na.rm = TRUE)
  
  # Reinsert NA values in the original positions
  result <- x
  result[!na_idx] <- x_normalized
  
  return(result)
}

# Sample data (vector)
set.seed(123)
data_vector <- runif(10)

# Perform quantile normalization
data_normalized <- quantile_normalize_vector(data_vector)

# Print the original and normalized data
print("Original Data:")
print(data_vector)

print("Quantile Normalized Data:")
print(data_normalized)

```
I think the above is correct by inspect qqnorm of data_vector and data_normalized



//june15_cv_pms_full.csv 64932719 => num vox = (1:50)*200, num samples = 2k train, 2k test.

```{r}
plot(res[1:3,])
par("mar")
```

#19 june

** I accidentally used num.vox.vec = (1:50)*200 for ridge but not other methods

```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/june15_cv_pms_full.csv")

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:3,])
num.vox.vec <- (1:100)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA','Ridge','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[4:6,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA','Ridge','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/june15_cv_pms_full.csv")
colnames(res) <- NULL
library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(c(res[1,seq(2,100,2)]), res[2,1:50],c(res[3,seq(2,100,2)])))
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA','Ridge','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(c(res[4,seq(2,100,2)]), res[5,1:50],c(res[6,seq(2,100,2)])))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA','Ridge','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

The jump is still there.

Running 
june19_cv_pms_full. 65002128 => fixing num.vox.vec and change cv.glmnet to glmnet

```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/june19_cv_pms_full.csv")

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:3,])
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA','Ridge','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[4:6,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA','Ridge','SPCA')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

This is totally weird. Something really happens at 2k variables

#21 June
##To do
1. Observe the jump => I think it's when p >= n in ridge prediction. For 600 samples and 2k samples, this happens exactly wheb n=p, for 6k training, it happens at p = 5.5k 
2. Do SPCA with 80% or 90% variance explained
3. Perform smoothing prior to SPCA


#2 july

## PCA and SPCA at 80% and 90%
Running 
[failed] july2_cv_pms8090_full 152987  => first ran into OOM issue, soenow im assigning all variables to the same variable to avoid multiple storing
//july2_cv_pms8090_full 236057
## Smoothing 
```{r}
# Function to apply 3D smoothing using a manual convolution with averaging kernel
smooth_3d_matrix_manual <- function(data) {
  # Define a 3x3x3 averaging kernel
  kernel <- array(1/27, dim = c(3, 3, 3))
  
  # Get the dimensions of the data
  dims <- dim(data)
  
  # Pad the data with zeros on all sides
  padded_data <- array(0, dim = dims + 2)
  padded_data[2:(dims[1]+1), 2:(dims[2]+1), 2:(dims[3]+1)] <- data
  
  # Initialize the smoothed data array
  smoothed_data <- array(0, dim = dims)
  
  # Apply the convolution manually
  for (x in 2:(dims[1]+1)) {
    for (y in 2:(dims[2]+1)) {
      for (z in 2:(dims[3]+1)) {
        # Extract the 3x3x3 neighborhood
        neighborhood <- padded_data[(x-1):(x+1), (y-1):(y+1), (z-1):(z+1)]
        
        # Compute the mean of the neighborhood
        smoothed_data[x-1, y-1, z-1] <- sum(neighborhood * kernel)
      }
    }
  }
  
  return(smoothed_data)
}

# Example usage with a 3D matrix
set.seed(123)
data_3d <- array(rnorm(5 * 5 * 5), dim = c(5, 5, 5))

# Apply the smoothing function
smoothed_data_3d <- smooth_3d_matrix_manual(data_3d)

# Print the original and smoothed data
print("Original Data:")
print(data_3d)

print("Smoothed Data:")
print(smoothed_data_3d)
```



#8 July

##PCA 80 and 90
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/july2_cv_pms8090_full.csv")

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(res[1:4,])
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 80', 'PCA 90','SPCA 80','SPCA 90')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(as.data.frame(res[5:8,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 80', 'PCA 90','SPCA 80','SPCA 90')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
Note that these methods don't do CV during predictions. 
Observable increase in RMSE when p -> n 

##Combine all results
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/june19_cv_pms_full.csv")
res2<- read.csv("/well/nichols/users/qcv214/pms2/pile/july2_cv_pms8090_full.csv")
res2<-  cbind(res2,matrix(data=NA,nrow=nrow(res2), ncol = (length(res)-length(res2))))
colnames(res2) <- colnames(res)

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[1:3,],res2[1:4,]))
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 100','Ridge','SPCA 100','PCA 80', 'PCA 90','SPCA 80','SPCA 90')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[4:6,],res2[5:8,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 100','Ridge','SPCA 100','PCA 80', 'PCA 90','SPCA 80','SPCA 90')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

#9 July
Tom suggests 2 packages for smoothing
`mmand`  => package mmand is not available for this version of R 
`https://github.com/jonclayden/mmand` for examples

and `fslr` (doing fsl in r) => package fslr is not available for this version of R

Maybe try another version of R?. Let me create a dummie file to run on the cluster. using `test_r.sh` and `code/test_r.R`

```{r}
install.packages("fslr")
```

Just realised that my data is stored in a 1d format, ie no 3D sense...
Perhaps I can fast load the data into a vector, stack as a 2D matrix as already done. Then for each row, turn it back into a nifti image using template, apply smoothing, turn it back into a vector

First need to check if vbm is already pre-smoothed tho... I think it's pre-smoothed. VBM involved smoothing techniques, and in `sample_brains/`, data also look smooth

Also `PMS` for loading images + other basic libraries and `mmand` and `fslr` are not avail in the same version of R so I can't run!!


#16 July
Let's try loading an old `mmand`

##Note
I ended up loading mmand locally, upload the package .tar.gz to the cluster and install it from there.
```{r}
packageurl <- "https://cran.r-project.org/src/contrib/Archive/mmand/mmand_1.6.1.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
```
```{r}
require(remotes)
install_version("mmand", version = "1.6.3", repos = "http://cran.us.r-project.org")
```

```{r}
# Install devtools package if not already installed
if (!requireNamespace("devtools", quietly = TRUE)) {
  install.packages("devtools")
}

# Load devtools library
library(devtools)
```
https://cran.r-project.org/src/contrib/Archive/mmand/mmand_1.6.2.tar.gz

```{r}
# Define the URL for the specific version of mmand
url <- "https://cran.r-project.org/src/contrib/Archive/mmand/mmand_1.6.1.tar.gz"

# Install the specific version from the URL
install.packages(url, repos = NULL, type = "source")
```
```{r}
# Replace 'path/to/mmand_1.6.2.tar.gz' with the actual path to the downloaded file
local_file_path <- "/well/nichols/users/qcv214/pms2/package/mmand_1.6.2.tar.gz"
install.packages(local_file_path, repos = NULL, type = "source")
```


##test mmand
from file `test_r.R`
```{r}
x <- seq(0, 4*pi, pi*2)
y1 <- cos(x) + runif(length(x),-0.2,0.2) *100
y2 <- cos(x) + runif(length(x),-0.5,0.5) *100
y3 <- cos(x) + runif(length(x),-0.9,0.9) *100

# y <- matrix(c(y1,y2,y3),byrow=TRUE,nrow=3)
#3rd dim, only 2 of them
y <- array(c(y1,y2,y3,y3,y2), dim = c(3,3,2))
y_smoothed <- gaussianSmooth(y, c(1,1,1))
print("done x ")
print(x)
print("done y ")
print(y)
print("done y___")
print(y_smoothed)
print("done")
```



//july17_cv_pms8090_full_smooth. 1511044 (previous job got oom halfway, at 16gb)

#20 July

##Observe effect of smoothing 80 and 90 
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/july2_cv_pms8090_full.csv")
res2<- read.csv("/well/nichols/users/qcv214/pms2/pile/july17_cv_pms8090_full_smooth.csv")
res2<-  cbind(res2,matrix(data=NA,nrow=nrow(res2), ncol = (length(res)-length(res2))))
colnames(res2) <- colnames(res)

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[1:4,],res2[1:4,]))
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 80', 'PCA 90','SPCA 80','SPCA 90','Smooth_PCA 80', 'Smooth_PCA 90','Smooth_SPCA 80','Smooth_SPCA 90')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[5:8,],res2[5:8,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 80', 'PCA 90','SPCA 80','SPCA 90','Smooth_PCA 80', 'Smooth_PCA 90','Smooth_SPCA 80','Smooth_SPCA 90')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```


##use Smoothed results
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/june19_cv_pms_full.csv")
res2<- read.csv("/well/nichols/users/qcv214/pms2/pile/july17_cv_pms8090_full_smooth.csv")
res2<-  cbind(res2,matrix(data=NA,nrow=nrow(res2), ncol = (length(res)-length(res2))))
colnames(res2) <- colnames(res)

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[1:3,],res2[1:4,]))
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 100','Ridge','SPCA 100','Smooth_PCA 80', 'Smooth_PCA 90','Smooth_SPCA 80','Smooth_SPCA 90')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[4:6,],res2[5:8,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 100','Ridge','SPCA 100','Smooth_PCA 80', 'Smooth_PCA 90','Smooth_SPCA 80','Smooth_SPCA 90')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
Smooth SPCA 90 is promising.

Smoothing works. Now we should look at the selected voxels. Plot this.

july20_cv_pms8090_full_smooth 1779108 (and viz july20)

//smooth_brain_gen.R 1852500

#22 July
The smooth brains look decent. Sample 1 and 2 looks fairly different tho, i.e. entirely different hotspots

##use Smoothed results
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/june19_cv_pms_full.csv")
res2<- read.csv("/well/nichols/users/qcv214/pms2/pile/july20_cv_pms8090_full_smooth.csv")
res2<-  cbind(res2,matrix(data=NA,nrow=nrow(res2), ncol = (length(res)-length(res2))))
colnames(res2) <- colnames(res)

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[1:3,],res2[1:5,]))
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 100','Ridge','SPCA 100','Smooth_PCA 80', 'Smooth_PCA 90','Smooth_SPCA 80','Smooth_SPCA 90','Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[4:6,],res2[6:10,]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 100','Ridge','SPCA 100','Smooth_PCA 80', 'Smooth_PCA 90','Smooth_SPCA 80','Smooth_SPCA 90','Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
Note June 19 uses 8k data. Need to tune it to 4k

//july22_cv_pms90_full 1939444[failed saved end result], 2026143 ==> has viz too


##use Smoothed results
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/july22_cv_pms90_full.csv")
res2<- read.csv("/well/nichols/users/qcv214/pms2/pile/july20_cv_pms8090_full_smooth.csv")
res2<-  cbind(res2,matrix(data=NA,nrow=nrow(res2), ncol = (length(res)-length(res2))))
colnames(res2) <- colnames(res)

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[1:3,],res2[c(2,4,5),]))
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[4:6,],res2[c(7,9,10),]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

#25 July
Use ridge for SPCA ===> nope, my original result was already using Ridge.

##To do
Compare this to pms
//july26_nbpms_full. 2575127 ===> failed to save pms.boot viz but everything else worked.


#27 July

##PMS
```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/july22_cv_pms90_full.csv")
res2<- read.csv("/well/nichols/users/qcv214/pms2/pile/july20_cv_pms8090_full_smooth.csv")
res2<-  cbind(res2,matrix(data=NA,nrow=nrow(res2), ncol = (length(res)-length(res2))))
colnames(res2) <- colnames(res)

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[1:3,],res2[c(2,4,5),]))
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[4:6,],res2[c(7,9,10),]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

```{r}
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/july22_cv_pms90_full.csv")
res2<- read.csv("/well/nichols/users/qcv214/pms2/pile/july20_cv_pms8090_full_smooth.csv")
res2<-  cbind(res2,matrix(data=NA,nrow=nrow(res2), ncol = (length(res)-length(res2))))
colnames(res2) <- colnames(res)
res3 <- read.csv("/well/nichols/users/qcv214/pms2/pile/july26_nbpms_full.csv")
res3<-  cbind(res3,matrix(data=NA,nrow=nrow(res3), ncol = (length(res)-length(res3))))
colnames(res3) <- colnames(res)

library(ggplot2)
library(tidyr)
# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[1:3,],res2[c(2,4,5),],res3[1:3, ]))
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge','PMS','PMS_holp','PMS_boots')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(2,7) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Assuming resdat is your dataframe
# Add a row identifier
resdat <- as.data.frame(rbind(res[4:6,],res2[c(7,9,10),],res3[4:6, ]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge','PMS','PMS_holp','PMS_boots')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")
# Create the line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line() +
  # scale_x_continuous(breaks = seq(0, max(as.numeric(resdat_long$column)), by = 100)) +
  # ylim(0,50) +
  theme_minimal() +
  scale_x_continuous(breaks=seq(0, 10000, 1000))+
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

Bottom two lines are still ridge and smooth SPCA
```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/july22_cv_pms90_full.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/july20_cv_pms8090_full_smooth.csv")
res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
colnames(res2) <- colnames(res)
res3 <- read.csv("/well/nichols/users/qcv214/pms2/pile/july26_nbpms_full.csv")
res3 <-  cbind(res3, matrix(data=NA, nrow=nrow(res3), ncol = (length(res) - length(res3))))
colnames(res3) <- colnames(res)

# Define custom color palette
custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
                   "Smooth_PCA 90" = "#984EA3", "Smooth_SPCA 90" = "#FF7F00",
                   "Smooth_Ridge" = "#FFFF33", "PMS" = "#A65628", 
                   "PMS_holp" = "#F781BF", "PMS_boots" = "#999999")

# First plot
resdat <- as.data.frame(rbind(res[1:3,], res2[c(2, 4, 5),], res3[1:3, ]))
num.vox.vec <- (1:50)*200
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge','PMS','PMS_holp','PMS_boots')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
resdat <- as.data.frame(rbind(res[4:6,], res2[c(7, 9, 10),], res3[4:6, ]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge','PMS','PMS_holp','PMS_boots')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

#2 Aug

i am starting to suspect if i Need to add mu to the data approx for PCA method in the lambda. If lambda is a proj matrix then its fine, but if its data approx then may need to add mu

e.g. lambda.80 <- `pca$rotation[, 1:num_components.90]%*% t(pca$rotation[, 1:num_components.90])` become `lambda.80 <- pca$rotation[, 1:num_components.90]%*% t(pca$rotation[, 1:num_components.90])` + mu


[failed, oom] aug2_mu_cv_pms90_full 3063946
[failed oom] aug2_mu_cv_pms90_full_smooth 3063953

[failed, solving error and mem] aug2_mu_cv_pms90_full 3445663=> test 40 slots
[failed, solving error and mem] aug2_mu_cv_pms90_full_smooth 3445656 => test 40 slots


#4 Aug

##Metrics
Let's look at the "relative importance index" as in PMS's paper

###Test RRI 
from GPT
```{r}
# Function to calculate the Relative Importance Index (RRI)
rri <- function(method, mask, num.vox = 10000) {
  # Rank the voxel values in descending order
  ranked_indices <- order(method, decreasing = TRUE)
  
  # Select the top num.vox indices
  top_voxels <- ranked_indices[1:num.vox]
  
  # Calculate the total number of voxels per region
  region_voxel_counts <- as.data.frame(table(mask))
  colnames(region_voxel_counts) <- c("Region", "Total_Voxels")
  
  # Calculate the number of selected top voxels per region
  top_voxel_counts <- as.data.frame(table(mask[top_voxels]))
  colnames(top_voxel_counts) <- c("Region", "Top_Voxels")
  
  # Merge the tables, ensuring all regions are included
  merged_counts <- merge(region_voxel_counts, top_voxel_counts, by = "Region", all.x = TRUE)
  merged_counts$Top_Voxels[is.na(merged_counts$Top_Voxels)] <- 0
  
  # Calculate the percentage of selected voxels per region
  merged_counts$Pct_Top_Voxels <- merged_counts$Top_Voxels / sum(merged_counts$Top_Voxels)
  
  # Calculate the overall percentage of voxels per region
  merged_counts$Pct_Total_Voxels <- merged_counts$Total_Voxels / sum(merged_counts$Total_Voxels)
  
  # Compute the Relative Importance Index (RRI)
  merged_counts$RRI <- merged_counts$Pct_Top_Voxels / merged_counts$Pct_Total_Voxels
  
  # Return the RRI for each region
  return(merged_counts[, c("Region", "RRI")])
}

# Example usage
method <- c(10, 5, 3, 4, 2, 6, 7, 8, 19, 11)
mask <- c(2, 2, 1, 1, 1, 3, 3, 3, 3, 3)
num.vox <- 5

rri(method, mask, num.vox)
```
I believe that this is correct. I have verified.

####Plotting
```{r}
library(ggplot2)
rri_result <- rri(method, mask, num.vox)

# Convert Region to a factor to maintain order in the plot
rri_result$Region <- factor(rri_result$Region, levels = rri_result$Region)

# Create the bar plot with numerical values on top of each bar
ggplot(rri_result, aes(x = Region, y = RRI)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  geom_text(aes(label = sprintf("%.2f", RRI)), 
            vjust = -0.3, color = "black", size = 3.5) +
  theme_minimal() +
  labs(title = "Relative Importance Index of Each Region",
       x = "Region",
       y = "Relative Importance Index")
```

Define a function called `rri_plot`
```{r}
# Load necessary library
library(ggplot2)

# Function to create the RRI bar plot
rri_plot <- function(rri_result, title_suffix) {
  # Convert Region to a factor with numeric levels to maintain order in the plot
  rri_result$Region <- factor(rri_result$Region, levels = sort(as.numeric(as.character(rri_result$Region))))
  
  # Create the title by concatenating the base title with the provided suffix
  plot_title <- paste("Relative Importance Index of Each Region:", title_suffix)
  
  # Create the bar plot with numerical values on top of each bar
  ggplot(rri_result, aes(x = Region, y = RRI)) +
    geom_bar(stat = "identity", fill = "skyblue", color = "black") +
    geom_text(aes(label = sprintf("%.2f", RRI)), 
              vjust = -0.3, color = "black", size = 3.5) +
    # geom_line() +
    geom_hline(aes(yintercept = 1, color = "RRI = 1"), linetype = "dashed", size = 1) +
    ylim(0,11) +
    theme_minimal() +
    labs(title = plot_title,
         x = "Region",
         y = "Relative Importance Index")
}
```

###apply this to our saved images

RRI of each method:
```{r}
#mask
res3.mask <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz','/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz'))
print(table(res3.mask)*100/length(res3.mask))
#smooth SPCA90
dat <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/smooth/july20_smooth_SPCA90.nii.gz','/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz'))
rri_result <- rri(dat, res3.mask, num.vox = 10000)
rri_plot(rri_result, "Smooth SPCA90")

#smooth SPCA80
dat <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/smooth/july20_smooth_SPCA80.nii.gz','/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz'))
rri_result <- rri(dat, res3.mask, num.vox = 10000)
rri_plot(rri_result, "Smooth SPCA80")

#Ridge
dat <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/july22_ridge.nii.gz','/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz'))
rri_result <- rri(dat, res3.mask, num.vox = 10000)
rri_plot(rri_result, "Ridge")

#Smooth ridge
dat <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/smooth/july20_smooth_ridge.nii.gz','/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz'))
rri_result <- rri(dat, res3.mask, num.vox = 10000)
rri_plot(rri_result, "Smooth Ridge")

#PMS
dat <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/july26_pms_hi.nii.gz','/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz'))
rri_result <- rri(dat, res3.mask, num.vox = 10000)
rri_plot(rri_result, "PMS")

#HOLP
dat <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/july26_pms_holp.nii.gz','/well/nichols/users/qcv214/bnn2/res3/res3mask.nii.gz'))
rri_result <- rri(dat, res3.mask, num.vox = 10000)
rri_plot(rri_result, "HOLP")
```

We can see that PMS and HOLP have RRI not so far from 1 in each region, whereas other methods have high RRI
Though HOLP shouldn't be using spatial info, so im not sure why it acts differently.



#6 aug
Assessing affect of re-centering in approx matrix on sub mask since full mask keeps going oom

First time, both faile due to singularity occurred when solving. I have changed theta.range starting from -4 to -1
//aug2_mu_cv_pms90_sub150  3710352
//aug2_mu_cv_pms90_sub150_smooth 3710342


##Adding mu

```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/aug2_mu_cv_pms90_sub150.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/aug2_mu_cv_pms90_sub150_smooth.csv")
res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
colnames(res2) <- colnames(res)

# Define custom color palette
# custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
#                    "Smooth_PCA 90" = "#984EA3", "Smooth_SPCA 90" = "#FF7F00",
#                    "Smooth_Ridge" = "#FFFF33", "PMS" = "#A65628", 
#                    "PMS_holp" = "#F781BF", "PMS_boots" = "#999999")

# First plot
resdat <- as.data.frame(rbind(res[1:5,], res2[c(1:5),]))
num.vox.vec <- (1:50)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','PCA 90 mu','SPCA 90','SPCA 90 mu','Ridge', 'Smooth_PCA 90', 'Smooth_PCA 90 mu','Smooth_SPCA 90','Smooth_SPCA 90 mu','Smooth_Ridge')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 5000, 1000)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
resdat <- as.data.frame(rbind(res[6:10,], res2[c(6:10),]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','PCA 90 mu','SPCA 90','SPCA 90 mu','Ridge', 'Smooth_PCA 90', 'Smooth_PCA 90 mu','Smooth_SPCA 90','Smooth_SPCA 90 mu','Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 5000, 1000)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
Mu and no mu almost no effect on screening

Here SPCA mu is better than SPCA at first, but eventually converge.

##Actually
We don't need mu, and it's wrong

Data approx matrix = Data*Projection matrix + mu 
`https://stats.stackexchange.com/questions/229092/how-to-reverse-pca-and-reconstruct-original-variables-from-several-principal-com`

but what we need is just the projection matrix, so we had been doing it right.


#8 Aug

Check for PSD and symmetry of Projectio Matrix

I want to assess the PD and symmetry property of the projection matrix of PCA (UUt) where U is the pc$rotation. Can you write me an assessment for two cases. The first case being X is a 10 x 15 matrix where each entry is iid uniform [0,1], apply PCA using prcomp, only keep rotation that explains 90% of cumulative variance, check if the matrix is symmetric and if it is positive definite or positive semi definite, do another case but using data from iid normal(0,1)
```{r}
# Load necessary library
library(ggplot2)

# Function to assess PD and symmetry properties of the projection matrix
assess_projection_matrix <- function(X) {
  # Apply PCA
  pca_result <- prcomp(X, center = TRUE, scale. = TRUE)
  # Calculate the cumulative variance explained
  cum_variance <- cumsum(pca_result$sdev^2 / sum(pca_result$sdev^2))
  # Keep components that explain 90% of the variance
  num_components <- which(cum_variance >= 0.90)[1]
  U <- pca_result$rotation[, 1:num_components]
  # Construct the projection matrix
  projection_matrix <- U %*% t(U)
  # Check if the matrix is symmetric
  is_symmetric <- all.equal(projection_matrix, t(projection_matrix))
  # Check if the matrix is positive definite or positive semi-definite
  eigenvalues <- round(eigen(projection_matrix)$values,8)
  is_positive_definite <- all(eigenvalues > 0)
  is_positive_semi_definite <- all(eigenvalues >= 0)
  
  # Print results
  cat("Symmetric:", is_symmetric, "\n")
  cat("Positive Definite:", is_positive_definite, "\n")
  cat("Positive Semi-Definite:", is_positive_semi_definite, "\n")
}

# Case 1: Uniform [0,1] Distribution
set.seed(123)
X_uniform <- matrix(runif(10 * 15), nrow = 10, ncol = 15)
cat("Case 1: Uniform [0,1] Distribution\n")
assess_projection_matrix(X_uniform)

# Case 2: Normal (0,1) Distribution
set.seed(123)
X_normal <- matrix(rnorm(10 * 15), nrow = 10, ncol = 15)
cat("Case 2: Normal (0,1) Distribution\n")
assess_projection_matrix(X_normal)
```
So, from manual inspection, UUT will have positive eigenvalues same as number of selected PCs, the rest will be 0 (or very near 0 by numerical computation). Making this projecting a PSD matrix.

"Any covariance matrix is symmetric and positive semi-definite"

Thus, our projection matrix must be a valid covariance!!

#12 Aug

Run stability (empirical)

Look at simulation, maybe just sub.mask
1. fix one region => with varying addition to observe sensitivity to SNR
2. or impose a spatial decay ("Gaussian blob") => to add spatial complexity
3. case of 2 disjoint regions?

We will do both


#Simulation study

##Look at data
Look at VBM summary of first two subjeccts
```{r}
part_list<-read.table('/well/nichols/users/qcv214/Placement_2/participant_list.txt', header = FALSE, sep = "", dec = ".") #4529 participants
part_list$exist_vbm <- file.exists(paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',part_list[,1],'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz'))
#These two are equal
part_use<-part_list[part_list$exist_vbm==1,] #4262 participants left
# part_use<-part_use[1:200,] #only take 200
part_use<-part_use[1:4000,] #only take 4k

agetab<-read.table(file = '/well/nichols/projects/UKB/SMS/ukb_latest-Age.tsv', sep = '\t', header = TRUE)
age_tab<-as.data.frame(matrix(,nrow = length(part_use$V1),ncol = 2)) #id, age, number of masked voxels
colnames(age_tab)[1:2]<-c('id','age')
age_tab$id<-part_use$V1
for(i in 1:length(part_use$V1)){
  age_tab$age[i]<-agetab$X21003.2.0[agetab$eid_8107==sub(".", "",age_tab$id[i])]
}
# age_tab.test <- age_tab[101:200,]
# age_tab <- age_tab[1:100,]
age_tab <- age_tab[1:2,]

list_of_all_images<-paste0('/well/win-biobank/projects/imaging/data/data3/subjectsAll/',age_tab$id,'/T1/T1_vbm/T1_GM_to_template_GM_mod.nii.gz')
sub.dat <- as.matrix(fast_read_imgs_mask(list_of_all_images,'/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
colnames(sub.dat) <- as.character(1:ncol(sub.dat))
```
So sub.dat is 2 x 15k, look at row-wise summary

```{r}
for( i in 1:2){
  print(summary(sub.dat[i,]))
}
```

```{r}
mask.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz','/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))

hist(mask.vec)
table(mask.vec)
```

By looking at FSLEYES and table(). I think I might use region 2, which is about 29% of the mask. Though it has very bad curvature.
I think I will use region 4 + 15, basically the centre of the brain, about 12% of the mask

```{r}
table(mask.vec[mask.vec %in% c(4,15)])
```


// sim_aug13_str3_pms90.csv 4652610 [from sim_binmask_oms2_pca] =>

```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug13_str3_pms90.csv")
# res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/aug2_mu_cv_pms90_sub150_smooth.csv")
# res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
# colnames(res2) <- colnames(res)

# Define custom color palette
# custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
#                    "Smooth_PCA 90" = "#984EA3", "Smooth_SPCA 90" = "#FF7F00",
#                    "Smooth_Ridge" = "#FFFF33", "PMS" = "#A65628", 
#                    "PMS_holp" = "#F781BF", "PMS_boots" = "#999999")

# First plot
# resdat <- as.data.frame(rbind(res[1:5,], res2[c(1:5),]))
resdat <- as.data.frame(rbind(res[1:3,]))
num.vox.vec <- (1:20)*100
colnames(resdat) <- num.vox.vec
# resdat$row_id <- c('PCA 90','PCA 90 mu','SPCA 90','SPCA 90 mu','Ridge', 'Smooth_PCA 90', 'Smooth_PCA 90 mu','Smooth_SPCA 90','Smooth_SPCA 90 mu','Smooth_Ridge')
resdat$row_id <- c('PCA 90','SPCA 90','Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 2000, 500)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
# resdat <- as.data.frame(rbind(res[6:10,], res2[c(6:10),]))
resdat <- as.data.frame(rbind(res[4:6,]))

colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 2000, 500)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
We can see that PCA and SPCA are better than ridge at first.
I think overall, we still want p >> n. Perhaps decrease n to about 500?


//sim_aug13_500_str3_ 4652784
//sim_aug13_500_str3_.... smooth. 4652832

```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug13_500_str3_pms90.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug13_500_str3_pms90_smooth.csv")
# res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
colnames(res2) <- colnames(res)

# Define custom color palette
# custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
#                    "Smooth_PCA 90" = "#984EA3", "Smooth_SPCA 90" = "#FF7F00",
#                    "Smooth_Ridge" = "#FFFF33", "PMS" = "#A65628", 
#                    "PMS_holp" = "#F781BF", "PMS_boots" = "#999999")

# First plot
resdat <- as.data.frame(rbind(res[1:3,], res2[c(1:3),]))
# resdat <- as.data.frame(rbind(res[1:3,]))
num.vox.vec <- (1:20)*100
colnames(resdat) <- num.vox.vec
# resdat$row_id <- c('PCA 90','PCA 90 mu','SPCA 90','SPCA 90 mu','Ridge', 'Smooth_PCA 90', 'Smooth_PCA 90 mu','Smooth_SPCA 90','Smooth_SPCA 90 mu','Smooth_Ridge')
resdat$row_id <- c('PCA 90','SPCA 90','Ridge','PCA 90 Smooth','SPCA 90 Smooth','Ridge Smooth')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 2000, 500)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
resdat <- as.data.frame(rbind(res[4:6,], res2[c(4:6),]))
# resdat <- as.data.frame(rbind(res[4:6,]))

colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge','PCA 90 Smooth','SPCA 90 Smooth','Ridge Smooth')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 2000, 500)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
Let's see if we can do double cv here... 

I have a feeling that the saving of spca smooth is. wrong for viz

Right now smoothing is done before defining output, meaning that smoothing makes voxels look even more similar, easier to predict
However
1. Should smoothing be done after defining response variable. This makes sense
    //sim_aug13_500_2_str3_   4654478
2. Should smoothing be done ONLY for screening but not prediction? This might make sense
  sim_aug13_500_3_str3_  4777365
```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug13_500_str3_pms90_smooth.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug13_500_2_str3_pms90_smooth.csv")
# res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
colnames(res2) <- colnames(res)

# Define custom color palette
# custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
#                    "Smooth_PCA 90" = "#984EA3", "Smooth_SPCA 90" = "#FF7F00",
#                    "Smooth_Ridge" = "#FFFF33", "PMS" = "#A65628", 
#                    "PMS_holp" = "#F781BF", "PMS_boots" = "#999999")

# First plot
resdat <- as.data.frame(rbind(res[1:3,], res2[c(1:3),]))
# resdat <- as.data.frame(rbind(res[1:3,]))
num.vox.vec <- (1:20)*100
colnames(resdat) <- num.vox.vec
# resdat$row_id <- c('PCA 90','PCA 90 mu','SPCA 90','SPCA 90 mu','Ridge', 'Smooth_PCA 90', 'Smooth_PCA 90 mu','Smooth_SPCA 90','Smooth_SPCA 90 mu','Smooth_Ridge')
resdat$row_id <- c('PCA 90 Smooth','SPCA 90 Smooth','Ridge Smooth','PCA 90 Smooth2','SPCA 90 Smooth2','Ridge Smooth2')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 2000, 500)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
resdat <- as.data.frame(rbind(res[4:6,], res2[c(4:6),]))
# resdat <- as.data.frame(rbind(res[4:6,]))

colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90 Smooth','SPCA 90 Smooth','Ridge Smooth','PCA 90 Smooth2','SPCA 90 Smooth2','Ridge Smooth2')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 2000, 500)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug13_500_str3_pms90.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug13_500_3_str3_pms90_smooth.csv")
# res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
colnames(res2) <- colnames(res)

# Define custom color palette
# custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
#                    "Smooth_PCA 90" = "#984EA3", "Smooth_SPCA 90" = "#FF7F00",
#                    "Smooth_Ridge" = "#FFFF33", "PMS" = "#A65628", 
#                    "PMS_holp" = "#F781BF", "PMS_boots" = "#999999")

# First plot
resdat <- as.data.frame(rbind(res[1:3,], res2[c(1:3),]))
# resdat <- as.data.frame(rbind(res[1:3,]))
num.vox.vec <- (1:20)*100
colnames(resdat) <- num.vox.vec
# resdat$row_id <- c('PCA 90','PCA 90 mu','SPCA 90','SPCA 90 mu','Ridge', 'Smooth_PCA 90', 'Smooth_PCA 90 mu','Smooth_SPCA 90','Smooth_SPCA 90 mu','Smooth_Ridge')
resdat$row_id <- c('PCA 90','SPCA 90','Ridge','PCA 90 Smooth3','SPCA 90 Smooth3','Ridge Smooth3')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 2000, 500)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
resdat <- as.data.frame(rbind(res[4:6,], res2[c(4:6),]))
# resdat <- as.data.frame(rbind(res[4:6,]))

colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge','PCA 90 Smooth','SPCA 90 Smooth','Ridge Smooth')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 2000, 500)) +
  # scale_color_manual(values = custom_colors) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
SPCA 90 smooth3 is good

I will re-run all the simulation results but with 4k voxels and viz

//sim_aug14_500_3_str smooth 4852824
//sim_aug14_500_str 4903912
//sim_aug14_500_2_str smooth 4903911
sim_aug14_500_str nbpms 4904081
Currently the viz of 2-3 smooths are the same.... they SHOULD be the same. Only difference is theta from cross-validation

#15 Aug

##Simulation results

```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug14_500_str3_pms90.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug14_500_2_str3_pms90_smooth.csv")
# res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
colnames(res2) <- colnames(res)
res3 <- (read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug14_500_3_str3_pms90_smooth.csv"))
# res3 <-  cbind(res3, matrix(data=NA, nrow=nrow(res3), ncol = (length(res) - length(res3))))
colnames(res3) <- colnames(res)

# Define custom color palette
custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
                   "Smooth_PCA 90" = "#984EA3", "Smooth_SPCA 90" = "#FF7F00",
                   "Smooth_Ridge" = "#FFFF33", "3 Smooth_PCA 90" = "#A65628", 
                   "3 Smooth_SPCA 90" = "#F781BF", "3 Smooth_Ridge" = "#999999")

# First plot
resdat <- as.data.frame(rbind(res[1:3,], res2[1:3,], res3[1:3, ]))
num.vox.vec <- (1:40)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge', '3 Smooth_PCA 90','3 Smooth_SPCA 90','3 Smooth_Ridge')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
resdat <- as.data.frame(rbind(res[4:6,], res2[c(4:6),], res3[4:6, ]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'Smooth_PCA 90','Smooth_SPCA 90','Smooth_Ridge', '3 Smooth_PCA 90','3 Smooth_SPCA 90','3 Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```


##with pms

```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)

# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug14_500_str3_pms90.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug14_500_str3_nbpms.csv")
# res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
colnames(res2) <- colnames(res)
res3 <- (read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug14_500_3_str3_pms90_smooth.csv"))
# res3 <-  cbind(res3, matrix(data=NA, nrow=nrow(res3), ncol = (length(res) - length(res3))))
colnames(res3) <- colnames(res)

# Define custom color palette
custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
                   "PMS" = "#984EA3", "HOLP" = "#FF7F00",
                   "PMS_rob" = "#FFFF33", "3 Smooth_PCA 90" = "#A65628", 
                   "3 Smooth_SPCA 90" = "#F781BF", "3 Smooth_Ridge" = "#999999")

# First plot
resdat <- as.data.frame(rbind(res[1:3,], res2[1:3,], res3[1:3, ]))
num.vox.vec <- (1:40)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'PMS','HOLP','PMS_rob', '3 Smooth_PCA 90','3 Smooth_SPCA 90','3 Smooth_Ridge')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
resdat <- as.data.frame(rbind(res[4:6,], res2[c(4:6),], res3[4:6, ]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'PMS','HOLP','PMS_rob', '3 Smooth_PCA 90','3 Smooth_SPCA 90','3 Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  ylim(20,75) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
## For 2nd Simulation Disjoint signal areas. 
I will use area 4 (centre-left) and 19 (bottom-right)
Everything is stored in `sim_dbmask.R` 
//... aug15_500_dbmask* 4911635

```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)
# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug15_500_dbmask_str3_pms90.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug15_500_dbmask_str3_nbpms.csv")
# res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
colnames(res2) <- colnames(res)
res3 <- (read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug15_500_dbmask_3_str3_pms90_smooth.csv"))
# res3 <-  cbind(res3, matrix(data=NA, nrow=nrow(res3), ncol = (length(res) - length(res3))))
colnames(res3) <- colnames(res)

# Define custom color palette
custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
                   "PMS" = "#984EA3", "HOLP" = "#FF7F00",
                   "PMS_rob" = "#FFFF33", "3 Smooth_PCA 90" = "#A65628", 
                   "3 Smooth_SPCA 90" = "#F781BF", "3 Smooth_Ridge" = "#999999")

# First plot
resdat <- as.data.frame(rbind(res[1:3,], res2[1:3,], res3[1:3, ]))
num.vox.vec <- (1:40)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'PMS','HOLP','PMS_rob', '3 Smooth_PCA 90','3 Smooth_SPCA 90','3 Smooth_Ridge')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
resdat <- as.data.frame(rbind(res[4:6,], res2[c(4:6),], res3[4:6, ]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'PMS','HOLP','PMS_rob', '3 Smooth_PCA 90','3 Smooth_SPCA 90','3 Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  ylim(20,75) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```
For this one, smoothing made everything worse
SPCA, PCA then PMS were the best respectively

But looking at viz, somehow HOLP and PMS did get all screening right.

***I think what to assess in Simulation is NOT predictive accuracy, but rather the selection.

##For 3rd Simulation: Gaussian blob
```{r}
library(oro.nifti)  # Ensure you have the oro.nifti package installed to handle NIfTI files

for(signal_strength in c(0,0.5,1,2,3,5)){

# Step 1: Load the mask and combine regions 4 and 15
res3_mask <- oro.nifti::readNIfTI('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz')

combined_region <- (res3_mask == 4) | (res3_mask == 15)

# Step 2: Calculate the center of mass for the combined region
region_coords <- which(combined_region, arr.ind = TRUE)
center_of_mass <- colMeans(region_coords)

# Step 3: Generate the Gaussian blob centered at the center_of_mass
# Define the standard deviation (spread) of the Gaussian
sigma <- 10  # Adjust this value based on the size of your ROI
# signal_strength <- 3  # Define a scaling factor to increase the signal strength

# Create a 3D array to hold the Gaussian blob
gaussian_blob <- array(0, dim = dim(res3_mask))

# Populate the Gaussian blob
for (i in 1:nrow(region_coords)) {
  coord <- region_coords[i, ]
  distance_sq <- sum((coord - center_of_mass)^2)
  gaussian_blob[coord[1], coord[2], coord[3]] <- signal_strength *exp(-distance_sq*10 / (2 * sigma^2))
}

# Step 4: Apply the Gaussian blob to the combined region
signal_mask <- combined_region * gaussian_blob

# Optional: Add the signal to the original mask or save it
res3_mask <- res3_mask * 0  # Start with a blank mask
res3_mask[combined_region] <- signal_mask[combined_region]

res3_mask@datatype = 16
res3_mask@bitpix = 32
writeNIfTI(res3_mask,paste0("/well/nichols/users/qcv214/pms2/viz/sim/res3_4n15_signal",signal_strength,"_gaussian_blob.nii.gz"))
}
```

This current implementation looks good, according to visualisation. 

Everything is stored in `sim_gaussmask.R` 
//... aug15_500_gaussmask* 4912481 ==> I think it's wrong. The addition of signal seems wrong. I will correct in `sim_gaussmask2.R`

###Correction
I have decided to generate a visualisation of voxel ranking with image files `_rank_`, saved in 

sim_binmask2.R. 4916105
sim_dbmask2.R. 4921442
sim_gaussmask2.R 4912985

###Gaussian blob
```{r}
# Load necessary libraries
library(ggplot2)
library(tidyr)
# Read data
res <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug15_500_gaussmask_str3_pms90.csv")
res2 <- read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug15_500_gaussmask_str3_nbpms.csv")
# res2 <-  cbind(res2, matrix(data=NA, nrow=nrow(res2), ncol = (length(res) - length(res2))))
colnames(res2) <- colnames(res)
res3 <- (read.csv("/well/nichols/users/qcv214/pms2/pile/sim_aug15_500_gaussmask_3_str3_pms90_smooth.csv"))
# res3 <-  cbind(res3, matrix(data=NA, nrow=nrow(res3), ncol = (length(res) - length(res3))))
colnames(res3) <- colnames(res)

# Define custom color palette
custom_colors <- c("PCA 90" = "#E41A1C", "SPCA 90" = "#377EB8", "Ridge" = "#4DAF4A",
                   "PMS" = "#984EA3", "HOLP" = "#FF7F00",
                   "PMS_rob" = "#FFFF33", "3 Smooth_PCA 90" = "#A65628", 
                   "3 Smooth_SPCA 90" = "#F781BF", "3 Smooth_Ridge" = "#999999")

# First plot
resdat <- as.data.frame(rbind(res[1:3,], res2[1:3,], res3[1:3, ]))
num.vox.vec <- (1:40)*100
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'PMS','HOLP','PMS_rob', '3 Smooth_PCA 90','3 Smooth_SPCA 90','3 Smooth_Ridge')

# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the first line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  labs(title = "Train RMSE", x = "No. Variables", y = "RMSE", color = "Method")

# Second plot
resdat <- as.data.frame(rbind(res[4:6,], res2[c(4:6),], res3[4:6, ]))
colnames(resdat) <- num.vox.vec
resdat$row_id <- c('PCA 90','SPCA 90','Ridge', 'PMS','HOLP','PMS_rob', '3 Smooth_PCA 90','3 Smooth_SPCA 90','3 Smooth_Ridge')
# Reshape the data to long format
resdat_long <- pivot_longer(resdat, cols = -row_id, names_to = "column", values_to = "value")

# Create the second line plot
ggplot(resdat_long, aes(x = as.numeric(column), y = value, group = row_id, color = as.factor(row_id))) +
  geom_line(size = 1) +
  theme_minimal() +
  scale_x_continuous(breaks = seq(0, 10000, 1000)) +
  scale_color_manual(values = custom_colors) +
  ylim(20,75) +
  labs(title = "Test RMSE", x = "No. Variables", y = "RMSE", color = "Method")
```

PMS and SPCA 90 are the best methods, need to judge from viz, but I bet PMS is better

#17 Aug

##4th simulation method: sparse
One other test method is to induce a random signal at every 10th
`sim_sparsemask2.R`  5766633 =>aug15
##Result analysis


(non-predictive) Metrics:

- `True % overlap = (TP)/(TP+FN)`
- `FPR = FP/(FP+TN)`. false positive rate (FPR) is the number of people who do not have the disease but are identified as having the disease (all FPs), divided by the total number of people who do not have the disease (includes all FPs and TNs).
    => note that our context is not voxel significance, but rather ranking, so FPR might not be needed
- `FDR = FP/(FP+TP)`.  false discovery rate (FDR) is the number of people who do not have the disease but are identified as having the disease (all FPs), divided by the total number of people who are identified as having the disease (includes all FPs and TPs).
- `ROC, AUC`?

1. Sensitivity => varying signal strength and evaluate the metrics, we can plot the graph for each method.
  Problem is we have too many methods and 3 metrics

2. Stability => either 1) use different subset of training, but our sample is already small. or 2) add random noise into some subjects 
  => I think these are two separate problems. 1) assess using smaller sample sizes, 2) assess nosiy data
  => for 1), we can do bootstrapping (sampling with replacement) which is valid
     for 2), we can do Noise simulation (varying strength of noise 0%, 5%, 10%) to assess robustness
   

###Sensitivity
1. Signal = 1, signal = 0.5, signal = 0

all is aug17
//`sim_gaussmask_sens.R` 5935510
//`sim_dbmask_sens.R` 5935504
//`sim_binmask_sens.R` 5935538    
//`sim_sparsemask_sens.R` 5935519

####Evaluation
```{r}
accuracy_cal <- function(rank.vec, mask.signal) {
  # Determine the number of top indices to consider
  n <- length(mask.signal)
  
  # Take the top n indices from rank.vec
  top_n <- rank.vec[1:n]
  
  # Compute True Positives (TP)
  TP <- length(intersect(top_n, mask.signal))
  
  # Compute Overlap as the percentage of true positives
  overlap <- round(TP * 100 / n, 3)
  
  # Compute False Positives (FP)
  FP <- length(setdiff(top_n, mask.signal))
  
  # Compute False Negatives (FN)
  FN <- length(setdiff(mask.signal, top_n))
  
  # Compute False Positive Rate (FPR)
  total_non_signal <- length(rank.vec) - n
  FPR <- round(FP*100 / total_non_signal, 3)
  
  # Compute False Discovery Rate (FDR)
  FDR <- round(FP*100 / (FP + TP), 3)
  
  # Return the results as a named list
  return(list(
    overlap = overlap,
    FPR = FPR,
    FDR = FDR
  ))
}

```

#####Test
```{r}
#Binmask
rank.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/sim/aug17_500_binmask_3_rank_str3_SPCA90_smooth.nii.gz','/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
mask.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz','/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
mask.index <- (mask.vec %in% c(4,15))
mask.signal <- which(mask.index)

accuracy_cal(rank.vec = rank.vec, mask.signal = mask.signal)

#dbmask
rank.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/sim/aug17_500_dbmask_3_rank_str3_SPCA90_smooth.nii.gz','/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
mask.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz','/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
mask.index <- (mask.vec %in% c(4,19))
mask.signal <- which(mask.index)

accuracy_cal(rank.vec = rank.vec, mask.signal = mask.signal)

#Gauss

rank.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/sim/aug17_500_gaussmask_3_rank_str3_SPCA90_smooth.nii.gz','/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
mask.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz','/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
mask.index <- (mask.vec %in% c(4,15))
mask.signal <- which(mask.index)

accuracy_cal(rank.vec = rank.vec, mask.signal = mask.signal)

#sparse mask
rank.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/viz/sim/aug17_500_sparsemask_3_rank_str3_SPCA90_smooth.nii.gz','/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
mask.signal <- seq(1,length(rank.vec), 10) #signal every 10th voxel

accuracy_cal(rank.vec = rank.vec, mask.signal = mask.signal)

#
```

I want this but for 

```{r}
# Define the parameters
signal_types <- c("binmask", "dbmask", "gaussmask", "sparsemask")
methods <- c("PCA90", "SPCA90", "PCA90_smooth", "SPCA90_smooth", "ridge", "pmshi", "holp")
signal_strengths <- c(5,3,2, 1, 0.5, 0)
base_path <- "/well/nichols/users/qcv214/pms2/viz/sim/aug17_500_"

# Initialize a data frame to store the results
results <- data.frame(
  SignalType = character(),
  Method = character(),
  SignalStrength = numeric(),
  Overlap = numeric(),
  FPR = numeric(),
  FDR = numeric(),
  stringsAsFactors = FALSE
)
```

```{r}
for (a in signal_types) {
  for (b in methods) {
    for (c in signal_strengths) {
      # Determine (d) based on the method
      if (grepl("_smooth$", b)) {
        d <- "3_"
      } else {
        d <- ""
      }

      # Construct the file path
      file_path <- paste0(base_path, a, "_", d, "rank_str", c, "_", b, ".nii.gz")

      # Load the rank vector
      rank.vec <- c(fast_read_imgs_mask(file_path, '/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
      rank.vec <- order(rank.vec, decreasing = TRUE)
      # Define the mask.signal based on signal type
      if (a == "binmask") {
        mask.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz', '/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
        mask.index <- (mask.vec %in% c(4, 15))
        mask.signal <- which(mask.index)
      } else if (a == "dbmask") {
        mask.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz', '/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
        mask.index <- (mask.vec %in% c(4, 19))
        mask.signal <- which(mask.index)
      } else if (a == "gaussmask") {
        mask.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz', '/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
        mask.index <- (mask.vec %in% c(4, 15))
        mask.signal <- which(mask.index)
      } else if (a == "sparsemask") {
        mask.signal <- seq(1, length(rank.vec), 10) # Signal every 10th voxel
      }

      # Compute accuracy metrics
      metrics <- accuracy_cal(rank.vec = rank.vec, mask.signal = mask.signal)

      # Store the results in the data frame
      results <- rbind(results, data.frame(
        SignalType = a,
        Method = b,
        SignalStrength = c,
        Overlap = metrics$overlap,
        FPR = metrics$FPR,
        FDR = metrics$FDR
      ))
    }
  }
}
# Save the results as a CSV file
write.csv(results, "/well/nichols/users/qcv214/pms2/viz/sim/sensitivity_results.csv", row.names = FALSE)

```

HOLP is always the best method with 100% recovery at high signal in all cases apart from Gaussian blob, followed by PMs
But PMS is the best in Gaussian blob

Our new methods are significantly inferior to PMS and HOLP

```{r}

# Optionally, plot the results using ggplot2
library(ggplot2)

# Example plot: Overlap vs. Signal Strength for each method and signal type
ggplot(results, aes(x = SignalStrength, y = Overlap, color = Method)) +
  geom_line() +
  facet_wrap(~ SignalType) +
  theme_minimal() +
  labs(title = "True % Overlap vs Signal Strength",
       x = "Signal Strength",
       y = "True % Overlap")
```

```{r}
# Load the ggplot2 library
library(ggplot2)

# Define a custom color palette with distinct colors
custom_colors <- c(
  "PCA90" = "#1b9e77",
  "SPCA90" = "#d95f02",
  "PCA90_smooth" = "#7570b3",
  "SPCA90_smooth" = "#e7298a",
  "ridge" = "#66a61e",
  "pmshi" = "#e6ab02",
  "holp" = "#a6761d"
)

# Unique Signal Types
signal_types <- unique(results$SignalType)

# Loop through each SignalType and create a separate plot
for (signal_type in signal_types) {
  # Filter the results for the current SignalType
  signal_data <- subset(results, SignalType == signal_type)
  
  # Create the plot with bolder lines and distinct colors
  p <- ggplot(signal_data, aes(x = SignalStrength, y = Overlap, color = Method)) +
    geom_line(size = 1.5) +  # Make the lines bolder with size = 1.5
    scale_color_manual(values = custom_colors) +  # Use custom colors
    theme_minimal() +
    labs(title = paste("True % Overlap vs Signal Strength -", signal_type),
         x = "Signal Strength",
         y = "True % Overlap",
         color = "Method") +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      axis.title = element_text(size = 12),
      axis.text = element_text(size = 10),
      legend.title = element_text(size = 12),
      legend.text = element_text(size = 10)
    )
  
  # Display the plot
  print(p)
  # Save the plot to a file
  # ggsave(filename = paste0("/well/nichols/users/qcv214/pms2/viz/sim/", signal_type, "_sensitivity_plot.png"),
  #        plot = p, width = 8, height = 6)
}
```

I want to do line plots for each mask

Recall, Gaussian Blob is wrong. for varying signal
Correting Gauss signal, with peak at 0,0.5,1,2,3,5 `7210345`

Adding signal 2,5 to the current analyses

###Stability

1) bootstrapping: I think it is quite uninteresting, but needed
    sample(1:250,500,replace = TRUE)
    
2) Adding noise. will it really be different from 0-strength signal?


Splitting training data into 2 sets, evaluate all methods with strength 0, 0.5,3
//sim_binmask_stab.R. 7210843

#20 Aug

Right now I only have 2 subsets of data for stability. Computing sd is not an option, so I will just calculate the difference between two subsets instead.

```{r}
# Define the parameters
signal_types <- c("binmask")
methods <- c("PCA90", "SPCA90", "PCA90_smooth", "SPCA90_smooth", "ridge", "pmshi", "holp")
signal_strengths <- c(3, 0.5, 0)
sets <- c(1, 2)
base_path <- "/well/nichols/users/qcv214/pms2/viz/sim/aug20_stability_"

# Initialize a data frame to store the results
results <- data.frame(
  SignalType = character(),
  Method = character(),
  SignalStrength = numeric(),
  Metric = character(),
  AbsoluteDifference = numeric(),
  stringsAsFactors = FALSE
)

for (a in signal_types) {
  for (b in methods) {
    for (c in signal_strengths) {
      # Determine (d) based on the method
      if (grepl("_smooth$", b)) {
        d <- "3_"
      } else {
        d <- ""
      }
      
      # Initialize vectors to store metrics for each set
      metrics_set1 <- NULL
      metrics_set2 <- NULL
      
      for (e in sets) {
        # Construct the file path for each set
        file_path <- paste0(base_path, a, "_", d, "rank_str", c, "_set", e, "_", b, ".nii.gz")
        
        # Load the rank vector
        rank.vec <- c(fast_read_imgs_mask(file_path, '/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))

        # Define the mask.signal based on signal type
        mask.vec <- c(fast_read_imgs_mask('/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz', '/well/nichols/users/qcv214/pms2/sub150_centre_mask.nii.gz'))
        mask.index <- (mask.vec %in% c(4, 15))
        mask.signal <- which(mask.index)

        # Compute accuracy metrics
        metrics <- accuracy_cal(rank.vec = rank.vec, mask.signal = mask.signal)

        # Store the metrics for each set
        if (e == 1) {
          metrics_set1 <- metrics
        } else {
          metrics_set2 <- metrics
        }
      }
      
      # Compute absolute differences between set 1 and set 2
      abs_diff_overlap <- abs(metrics_set1$overlap - metrics_set2$overlap)
      abs_diff_FPR <- abs(metrics_set1$FPR - metrics_set2$FPR)
      abs_diff_FDR <- abs(metrics_set1$FDR - metrics_set2$FDR)
      
      # Store the results in the data frame
      results <- rbind(results, data.frame(
        SignalType = a,
        Method = b,
        SignalStrength = c,
        Metric = "Overlap",
        AbsoluteDifference = abs_diff_overlap
      ))
      
      # results <- rbind(results, data.frame(
      #   SignalType = a,
      #   Method = b,
      #   SignalStrength = c,
      #   Metric = "FPR",
      #   AbsoluteDifference = abs_diff_FPR
      # ))
      # 
      # results <- rbind(results, data.frame(
      #   SignalType = a,
      #   Method = b,
      #   SignalStrength = c,
      #   Metric = "FDR",
      #   AbsoluteDifference = abs_diff_FDR
      # ))
    }
  }
}
```
```{r}
# Load the ggplot2 library
library(ggplot2)

# Define a custom color palette with distinct colors
custom_colors <- c(
  "PCA90" = "#1b9e77",
  "SPCA90" = "#d95f02",
  "PCA90_smooth" = "#7570b3",
  "SPCA90_smooth" = "#e7298a",
  "ridge" = "#66a61e",
  "pmshi" = "#e6ab02",
  "holp" = "#a6761d"
)

# Unique Signal Types
signal_types <- unique(results$SignalType)

# Loop through each SignalType and create a separate plot for each metric
for (signal_type in signal_types) {
  for (metric in unique(results$Metric)) {
    # Filter the results for the current SignalType and Metric
    signal_data <- subset(results, SignalType == signal_type & Metric == metric)
    
    # Create the plot with bolder lines and distinct colors
    p <- ggplot(signal_data, aes(x = SignalStrength, y = AbsoluteDifference, color = Method)) +
      geom_line(size = 1.5) +  # Make the lines bolder with size = 1.5
      scale_color_manual(values = custom_colors) +  # Use custom colors
      theme_minimal() +
      labs(title = paste(metric, "Absolute Difference vs Signal Strength -", signal_type),
           x = "Signal Strength",
           y = paste(metric, "Absolute Difference"),
           color = "Method") +
      theme(
        plot.title = element_text(size = 14, face = "bold"),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10),
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10)
      )
    
    # Display the plot
    print(p)
  }
}
```


#21 Aug
Real-data simulation signal

// `sim_age_create_signal_SPCA_smooth.R`. 7865474
'/well/nichols/users/qcv214/pms2/viz/sim/aug21_500_age_rank_SPCA90_smooth'

Use SPCA smooth on age prediction, then select top 1600 voxels to create a flat signal
`sim_SPCAmask_sens.R` 7866676 => this is label aug17








